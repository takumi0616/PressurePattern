機械学習手法による日本の気圧配置の分類
Applying a Machine Learning Technique to Classification of Japanese Pressure Patterns

著者・所属・連絡先

- H. Kimura1\*, H. Kawashima1,2, H. Kusaka2, H. Kitagawa1,2
- 1 筑波大学 システム情報工学研究科（University of Tsukuba, Graduate School of Systems and Information Engineering）
  - Email: hkimu@kde.cs.tsukuba.ac.jp; kawasima@kde.cs.tsukuba.ac.jp; kitagawa@kde.cs.tsukuba.ac.jp
- 2 筑波大学 計算科学研究センター（Center for Computational Sciences, University of Tsukuba）
  - Email: kusaka@ccs.tsukuba.ac.jp
- \*責任著者（Corresponding author）

出典

- Data Science Journal, Volume 8, 2009 年 3 月 30 日, S59–S67

要旨（Abstract）
気候研究において、気圧配置はしばしば非常に重要である。例えば「日本の西で低圧、東で高圧（冬型の気圧配置）」といった特定の気圧配置の日を知る必要があるとき、気候学者は膨大な数の地上天気図を目視で確認しなければならない。本研究ではこの問題を克服するため、機械学習手法の一つであるサポートベクターマシン（SVM）を用いた自動分類システムを提案する。気圧配置を「冬型」と「非冬型」の 2 クラスに分類した。学習データと評価データには 1981–2000 年の JRA-25 データセットを用いた。実験評価の結果、本手法は F-measure が 0.8 を超える性能を得た。また、学習データの違いにより結果に変動が生じることを確認した。

キーワード

- サポートベクターマシン（SVM）
- 機械学習
- 気圧配置
- 分類

図表についての注記
本文で言及される図（Fig. 1–7）や表（Table 1–4）は、原論文 PDF の画像に依存しており本ファイルには含まれていません。本文の説明・キャプション情報はテキストとして反映しています。

1. はじめに（Introduction）
   コンピュータは大量のデータを高速に処理できる。自然科学の分野では、研究者が膨大なデータの解析にコンピュータ技術を用い始めている。気候学においても、大規模データセットの統計解析や数値シミュレーションはコンピュータで実施されている。本研究では、気候学における気圧配置に関する検討を行う。

気候研究では、気圧配置はしばしば極めて重要である。気圧配置は 15 の型に分類される（Yoshino, 2002）。日本周辺で特定の気圧配置、例えば「日本の西で低圧・東で高圧（日本の冬型）」や「日本の南で高圧・北で低圧（日本の夏型）」の日を知る必要がある場合、膨大な地上天気図を目視で確認する必要があり、労力がかかる。

この問題を解決するため、コンピュータサイエンス分野で発展した機械学習を用いた自動分類手法を提案する。本研究では SVM を用い、気圧配置を「冬型」と「非冬型」に分類する。学習データと評価データには 1981–2000 年の JRA-25 データセットを使用し、SVM ライブラリとして LIBSVM（Chang & Lin, 2000）を用いた。

2. 研究目的と用いたデータ（Research Objective and Data Used）
   2.1 目的（Objective）
   気候学では多くの気圧配置があり、15 型に分類される（Yoshino, 2002）。さらに、単一の型に属さない事例は「遷移型」または「混合型」として分類され、これらは 15 型のうち 2 型の組み合わせである。

本研究では日本の冬型気圧配置を対象とする。Fig. 1 は日本の冬型の地上天気図例を示す。冬型の特徴は、日本の西側で低圧、東側で高圧である。冬型が発生すると、北から寒気が吹き込み気温が低下し、日本海側では降雪が多くなる。

本研究の目的は、膨大な気象データを「冬型」と「非冬型」の 2 クラスに自動分類するシステムを構築することである。

2.2 データ（Data）
気象データには JRA-25（Japanese 25-year Re-Analysis）を用いた。JRA-25 は JMA（気象庁）と CRIEPI（電力中央研究所）による 1979–2004 年の再解析プロジェクト（Onogi et al., 2005）であり、6 時間ごとにアーカイブされている。したがって、1 日に 4 つのデータセットがある。データ形式は WMO 標準の GRIB（GRIdded Binary）である。

本研究では、各日 09JST（日本標準時 09 時）のデータ（1 日 1 データ）を使用した。冬型の特徴は海面更正気圧（SLP）に表れるため、JRA-25 のカテゴリ anl_p から SLP を抽出した。anl_p には SLP のほか気温や湿度など多数の要素が含まれる。wgrib プログラムを用いて GRIB をバイナリに変換し、要素コード「PRMSL」を指定して SLP 数値データを抽出した。

抽出した SLP は 145×288 = 41,760 点の全球データである。本研究では日本周辺（北緯 15–60°、東経 105–175°）に限定し、37×57 = 2,109 点を用いた。

3. 研究方法（Study Method）
   3.1 サポートベクターマシン（SVM）
   SVM は 2 クラス分類を扱う機械学習手法で、テキスト・音声認識など多分野で用いられている（Tsuda, 2000）。

SVM では学習データ（トレーニングデータ） {}{(x_i, y_i)} を用いる。ここで x_i はベクトル、y_i ∈ {−1, 1} はクラスを表す。SVM は学習データに基づいて、サポートベクタからのマージン（超平面からの距離）を最大化する超平面を構成する（Tsuda, 2000）。Fig. 2 は線形分離の概念図で、記号「○」はクラス 1、「☆」はクラス 2 を表し、各クラスの陰影付き記号がサポートベクタである。

線形分離が不可能な場合（Fig. 3）、非線形分離を適用する。まず非線形写像により高次元空間へ写像し、その空間で超平面により分離する。高次元ベクトル Φ(x_i), Φ(x_j) の内積計算が必要だが、カーネル関数 K(x_i, x_j) = Φ(x_i)·Φ(x_j) により原空間での計算で済む（Tsuda, 2000）。本研究では代表的な非線形カーネルである RBF（Radial Basis Function）カーネルを用いた。RBF カーネルは次式で与えられる：
K(x_i, x_j) = exp(−δ · ∥x_i − x_j∥^2) … (1)
ここで x_i, x_j は各学習データのベクトル、δ はパラメータである。RBF カーネルの δ は適切に選ぶ必要があり、採用値は 4.4 節に示す。

SLP データは 37×57 = 2,109 格子点であり、学習・推論とも 1×2109 の 2,109 次元ベクトルとして扱う。SVM により、この 2,109 次元ベクトルを「冬型」または「非冬型」に分類する。SVM による分類処理は以下の通り：

1. ベクトルとクラスの組から学習データを作成する。
2. 学習データから SVM で分類器を生成する。
3. 生成した分類器でテストデータを分類する。

3.2 学習データの生成（Generation of Training Data）
SVM は学習データから分類器を構築するため、学習データの違いが分類結果に影響する。そこで複数の学習データ集合を作成し、分類結果を比較した。

各データが正例（冬型）か負例（非冬型）かの決定には、Yoshino (2002) の分類を用いた。Yoshino (2002) は気圧配置を 15 型に分類し、単一型に属さない事例は遷移型・混合型（15 型の 2 型の組み合わせ）として扱う。以下の区分を定義する：

- Case-A: 冬型（winter type）
- Case-B: 遷移型または混合型（冬型と他型の組み合わせ）
- Case-C: 6 月・7 月・8 月（夏季で冬型なし）
- Case-D: 上記以外

Table 2 に基づき、Case-A〜D から複数の学習データ ID を作成し、各 ID ごとに正例・負例の組み合わせを定義した（例：ID1 は正例=Case-A,B、負例=Case-C,D など）。これにより Case-B, C, D の取り扱いが結果に与える影響を検討した。

4. 実験（Experiment）
   4.1 実験データと手順（Experimental Data and Procedure）
   1981–1990 年の SLP データを学習データ、1991–2000 年の SLP データをテストデータとして分類実験を行った。

分類器は線形カーネルと RBF（非線形）カーネルの 2 通りを評価した。非線形カーネルのパラメータは本研究の設定で最も高精度となる値を用いた（以降、非線形カーネルは RBF を指す）。SVM ライブラリには LIBSVM（Chang & Lin, 2000）を使用した。

手順：

1. 1981–1990 年の SLP から学習データを作り、分類器を生成する。
2. 1991–2000 年のテストデータを生成した分類器で分類する。
3. Yoshino (2002) の分類と比較して結果を評価する。

4.2 分類結果の評価（Evaluation of Classification Results）
評価は「弱い冬型」と「強い冬型」の 2 通りで行った（Table 3, Table 4）。

1. 弱い冬型の評価：Case-A と Case-B を冬型、Case-C と Case-D を非冬型として評価。一般に、冬型と他型の組み合わせ（遷移・混合）は冬型として扱われるため、Case-B を冬型に含めた「弱い冬型」を評価できる。
2. 強い冬型の評価：Case-A を冬型、Case-B, C, D を非冬型として評価。Yoshino (2002) で冬型とされたもののみを冬型とし、より厳密な「強い冬型」を評価する。

混同行列の定義：

- TP（真陽性）, FP（偽陽性）, FN（偽陰性）, TN（真陰性）

指標：

- Precision = TP / (TP + FP) … (2)
- Recall = TP / (TP + FN) … (3)
- F-measure = 2·TP / (2·TP + FP + FN) … (4)
  （F-measure は Precision と Recall の調和平均：Witten & Frank, 2005）

  4.3 実験：複数学習データの比較（Comparison Using Multiple Training Data）
  Table 2 の各学習データ ID を用いて分類器を生成し、以下を実施：

- 実験 1：弱い冬型（Table 3）による評価
- 実験 2：強い冬型（Table 4）による評価

  4.4 実験結果（Results of Experiment）
  非線形（RBF）カーネルのパラメータ δ は 10×10^−6 とした。

  4.4.1 実験 1（弱い冬型評価）の結果
  Fig. 4 に線形カーネル、Fig. 5 に非線形カーネルの結果を示す。要約：

- 学習 ID 1, 3：Precision・Recall とも概ね高く、最大の F-measure を得た。
- 学習 ID 2, 9：Precision は低いが Recall は 1.0（偽陰性なし）。ただし F-measure は最小。
- 学習 ID 4, 6：他の学習集合と比較して Precision が高く、Recall は低い。
- 学習 ID 5：概ね平均的。
- 学習 ID 7, 10：Precision は高く、Recall はやや低い。
- 学習 ID 8：線形と非線形で Precision と Recall の大小関係が逆転。非線形では最小の F-measure。

  4.4.2 実験 2（強い冬型評価）の結果
  Fig. 6 に線形カーネル、Fig. 7 に非線形カーネルの結果を示す。要約：

- 学習 ID 1, 3：Precision は低く、Recall は高い。
- 学習 ID 2, 9：Precision は低く、Recall はほぼ 1.0。F-measure は最小。
- 学習 ID 4, 6：Precision・Recall とも平均的に高く、最大の F-measure を得た。
- 学習 ID 5：平均的。
- 学習 ID 7, 10：Precision はやや低いが、Recall は高い。
- 学習 ID 8：線形では平均的。非線形では Recall は高いが、Precision と F-measure は低い。

  4.4.3 実験の総合結果（General Results of Experiments）
  SVM による冬型分類は、弱い冬型評価では F-measure が 0.8 を超え、強い冬型評価では 0.7 未満であった。学習 ID 8 を除き、線形と非線形の精度差は小さかった。

本研究では Yoshino (2002) の分類を基準として正例・負例を定めた。一定の基準に基づく正負例の選択により、コンピュータによる分類が可能であることを示した。

4.4 考察（Consideration）
弱い冬型評価の最大 F-measure は、強い冬型評価の最大値を 0.1 以上上回った。Case-A〜D の定義（正負例の切り方）は、強い冬型より弱い冬型の評価に適していたと考えられる。

Precision の観点では、学習 ID 4, 6, 7, 10 が高かった。ID 4, 6 は評価で Case-B を冬型とした一方、学習では Case-B を非冬型（負例）として扱った。すなわち、学習を厳しめ、評価を相対的に緩めた条件となっている。ID 7, 10 では学習に Case-B を含めないことで、Case-B に起因する誤検出が抑制されたと考えられる。ただし、これらは Recall が低く、「冬型と判定されたデータの確からしさを重視」する一方で、「冬型の取りこぼし」は増える傾向がみられる。

Recall の観点では、特に負例を Case-C（夏季）に限定した学習集合で Recall が 1.0 近くに達した。これは「冬と夏」という明確な 2 クラスの識別になっていることを示唆し、冬データが夏クラスに誤分類されにくいことは妥当である。しかし Precision は低く、冬型のカバレッジは高いが誤検出も多い設定と言える。

学習 ID 1 と 3、4 と 6、7 と 10 の間で精度差が小さく、Case-C（6–8 月）の寄与は学習上それほど重要ではない可能性がある。

学習 ID 8（負例なし）では線形・非線形で Precision/Recall の位置が逆転した。ID 8 に Case-C または Case-D を加えた ID 5, 6 の結果から、ID 8 の挙動は負例の不在に起因すると考えられる。

偽陽性（FP）には Yoshino (2002) の台風型が含まれるものがあり、低気圧（台風）の影響により冬型へ誤分類された可能性がある。

5. 結論と今後の課題（Conclusion and Future Work）
   SVM を用いて、日本周辺の特定の気圧配置である「冬型」の自動検出を行った。正負例の選択には Yoshino (2002) を用いた。複数の学習データから分類器を生成し、分類結果を比較した。

実験の結果、F-measure は 0.8 を超えた。一定の基準に基づく正負例の選択により、コンピュータによる分類が可能であることを示した。分類精度は分類器生成に用いる学習データに依存した。

今後は、分類精度の向上と他の気圧配置の分類に取り組む。日本周辺の格子領域（緯度・経度）の変更や、気圧以外の有用な要素の利用により精度が向上するかを検討する。他の気圧配置を分類する際には、各配置を特徴付ける要素が異なるため、適切な要素選択が重要である。

6. 謝辞（Acknowledgements）
   本研究は、日本学術振興会（JSPS）科学研究費補助金（#20240010）および文部科学省「重点領域研究」（#19024006）の支援を受けた。

7. 参考文献（References）

- Chang, C.-C., & Lin, C.-J. (2000). LIBSVM: A Library for Support Vector Machines. http://www.csie.ntu.edu.tw/~cjlin/libsvm/
- Witten, I. H., & Frank, E. (2005). Data Mining. Morgan Kaufmann Publishers.
- Onogi, K., et al. (2005). JRA-25: Japanese 25-year re-analysis project - progress and status. Quarterly Journal of the Royal Meteorological Society, 131, 3259–3268.
- Tsuda, K. (2000). Overview of Support Vector Machine. Journal of IEICE, 83(6), 460–466.
- Yoshino, M., & Japanese Study Group for Climate Impact and Application (Eds.). (2002). Climate in Japan, Part I. Ninomiya-Shoten Publishers Ltd.

図キャプション（本文記述）

- Fig. 1. 地上天気図（日本の冬型の例）
- Fig. 2. SVM による線形分離の概念（○: クラス 1、☆: クラス 2；陰影付きはサポートベクタ）
- Fig. 3. 非線形分離の概念（高次元空間への写像と超平面分離）
- Fig. 4. 実験 1（弱い冬型評価）：線形カーネルの結果
- Fig. 5. 実験 1（弱い冬型評価）：非線形カーネルの結果
- Fig. 6. 実験 2（強い冬型評価）：線形カーネルの結果
- Fig. 7. 実験 2（強い冬型評価）：非線形カーネルの結果

表説明（本文記述）

- Table 1. Yoshino (2002) による気圧配置ケース定義（Case-A: 冬型、Case-B: 冬型を含む遷移/混合型、Case-C: 6–8 月、Case-D: その他）
- Table 2. Table 1 に基づく学習データ ID と正例/負例の対応
- Table 3. 弱い冬型評価の混同行列（Case-A,B を冬型、Case-C,D を非冬型）
- Table 4. 強い冬型評価の混同行列（Case-A を冬型、Case-B,C,D を非冬型）
