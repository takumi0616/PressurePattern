---
title: 複数ラベル天候認識のためのCNN-RNNアーキテクチャ（A CNN-RNN Architecture for Multi-Label Weather Recognition）
authors:
  - Bin Zhao
  - Xuelong Li
  - Xiaoqiang Lu (責任著者)
  - Zhigang Wang
affiliations:
  - a: School of Computer Science and Center for OPTical IMagery Analysis and Learning (OPTIMAL), Northwestern Polytechnical University, Xi’an 710072, Shaanxi, P. R. China.
  - b: Xi’an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi’an 710119, Shaanxi, P. R. China.
contact:
  - Email: luxq666666@gmail.com (Xiaoqiang Lu)
arxiv: arXiv:1904.10709v1 [cs.CV] 24 Apr 2019
date: April 25, 2019
---

# 複数ラベル天候認識のためのCNN-RNNアーキテクチャ

著者: Bin Zhao a, Xuelong Li b, Xiaoqiang Lu b,∗, Zhigang Wang a

所属:
- a: School of Computer Science and Center for OPTical IMagery Analysis and Learning (OPTIMAL), Northwestern Polytechnical University, Xi’an 710072, Shaanxi, China
- b: Xi’an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi’an 710119, Shaanxi, China

責任著者: Xiaoqiang Lu（Email: luxq666666@gmail.com）

プレプリント提出先: Journal of LaTeX Templates  
提出日: 2019年4月25日  
arXiv:1904.10709v1 [cs.CV] 2019年4月24日

---

## 要旨

天候認識は私たちの日常生活や多くのコンピュータビジョン応用において重要である。しかし、単一画像から天候状態を認識することは依然として困難であり、十分に研究されていない。一般に、従来の多くの研究は天候認識を単一ラベル分類タスクとして扱い、すなわち、ある画像が特定の天候クラスに属するか否かを判定してきた。この扱いは常に適切とは限らない。なぜなら、単一の画像に複数の天候状態が同時に現れることがあり得るからである。本研究では、天候認識を複数ラベル分類タスクとして捉え、すなわち、画像に表示されている天候状態に応じて複数のラベルを割り当てることを初めて試みる。具体的には、CNN-RNNに基づく複数ラベル分類手法を提案する。畳み込みニューラルネットワーク（CNN）はチャネル方向のアテンションモデルによって拡張され、最も関連の強い視覚特徴を抽出する。リカレントニューラルネットワーク（RNN）はこれらの特徴をさらに処理し、天候クラス間の依存性を掘り起こす。最終的に天候ラベルは段階的に予測される。加えて、天候認識タスクのための2つのデータセットを構築し、異なる天候条件間の関係を探索する。実験結果は、提案手法の優位性と有効性を示す。新たに構築したデータセットは https://github.com/wzgwzg/Multi-Label-Weather-Recognition で公開予定である。

キーワード: 天候認識、複数ラベル分類、畳み込みLSTM

---

## 1. 序論

天候状態は、衣服の選択、移動、太陽エネルギー技術など、私たちの日常生活や生産に多方面で影響を与える [1]。したがって、自動的に天候状態を取得することは多様な人間活動にとって重要である。天候認識の1つの解決策は、各種ハードウェアを活用することである。しかし、これらの機器は一般に高価で、専門家による保守が必要である。代替の方策として、コンピュータビジョン技術 [2, 3] を用いてカラー画像から天候状態を認識することが挙げられる。今日では監視カメラが遍在しており、このコンピュータビジョンによる解が現実的になっている。日常生活への指針的な意義に加え、天候認識は他の多くのコンピュータビジョン応用 [4, 5, 6, 7]（例えば画像検索 [8]、画像復元 [9]、屋外監視システムの信頼性向上 [3]）にとっても重要な機能である。ロボットビジョン [10, 11] や自動車の運転支援システム [12, 13] も天候認識の恩恵を受ける。以上より、屋外画像からの天候認識は大きな研究的意義を持つと結論できる。

### 1.1. 動機と概観

天候認識は顕著な価値を持つにもかかわらず、この問題に取り組んだ研究は限られている。従来のいくつかの研究 [12, 14, 15, 16] は車載カメラで撮影された画像から天候状態を認識することに注力した。他にも、単一の屋外画像から天候認識を試みた研究 [17, 18, 1] がある。これらはいずれも天候認識を単一ラベル分類タスク（本論文では「天候ラベル」は天候カテゴリを意味する）として扱い、すなわち画像が特定の天候カテゴリに属するか否かを判定してきた。

しかし、天候認識を単一ラベル分類問題として捉えるのは常に適切ではない。その不適切さの主な理由は2つある。第一の理由は不確実性であり、すなわち、いくつかの天候カテゴリ間のクラス境界は本質的に曖昧であるということだ。図1から分かるように、図1(a)から(f)への変化は、純粋な晴天（図1(a)）と明らかな曇天（図1(f)）の間に一連の状態が存在することを示している。中間的な天候状態（図1(c),(d),(e)）に対して、晴か曇かを判定するのは困難である [2]。このような境界サンプルの不確実性は、真のラベルを決めることを人間にとっても難しくし、従来研究の多くはこの問題への解決策を示していない。第二の欠点は不完全性であり、すなわち単一の天候ラベルでは、与えられた画像に対する天候状態を包括的に記述できないということである。例えば、図1(g),(h),(i)では霞（haze）の視覚効果が明らかであるが、これら3枚の画像を比較すると、図1(g)はより晴れており、図1(h)はより曇天に見え、図1(i)は雪景色であるように見える。したがって、霞の単一ラベルだけではこれら3枚の違いを表現できない。

図2に示すように、天候認識において重要な領域が存在する。例えば、青空は晴天の判定に、地面の雪は雪天の推定に重要である。[2] でも、このような天候の手がかり（cues）の重要性が強調されている。よって、天候の手がかりを識別的にし、画像の空間情報を保持することが必要である。

上記の2つの理由に動機づけられ、本研究では天候認識を複数ラベル分類問題として捉え、画像に表示される天候状態に応じて複数ラベルを割り当てることを提案する。具体的には、CNN-RNNアーキテクチャによりこれを実現する。直観は2点にある。第一に、従来研究の多くは手作り（hand-crafted）の天候特徴 [1], [20] の活用に焦点を当ててきたが、これらは天候認識で望ましい結果を達成できなかった。近年の畳み込みニューラルネットワーク（CNN）の大きな成功に触発され、我々はCNNを天候特徴抽出器として用いる。第二に、天候領域のラベルは強い同時出現（co-occurrence）依存性を示す。例えば、雪と曇はしばしば同時に現れるが、雨と晴はほとんど共起しない。依存性モデリング [21, 22] におけるリカレントニューラルネットワーク（RNN）の成功に触発され、我々はRNNを用いてラベル間の依存性をモデル化し、段階的に天候ラベルを予測することを提案する。このようにして、後続のラベルを予測する際に、過去の情報を暗黙に取り込んだ以前の隠れ状態を参照できる。

本研究では、チャネル方向のアテンションモデルを設計して、天候認識にとってより識別的な特徴を活用する。また、空間情報を保持するために、標準RNNではなく畳み込みLSTM（Convolutional LSTM）[23] をCNN-RNNアーキテクチャに組み込む。畳み込みLSTMは状態間および入力-状態間のいずれも畳み込み演算を用い、全結合型LSTM（FC-LSTM）[23] よりも優れた時空間情報を捉える。

さらに、天候認識タスクでデータセットが不足していることを踏まえ、本研究では2つの新しいデータセットを構築する。1つは既存の一時的属性（transient attribute）データセット [19] を変換したもので、7つの天候カテゴリから約8千枚の画像を含む。もう1つはゼロから構築したもので、5つの天候カテゴリから1万枚の画像を含む。

### 1.2. 貢献

本研究の主な貢献は以下の3点に要約される。
1) 天候認識を単一ラベル分類として扱う欠点と、異なる天候条件間の共起関係を分析し、天候認識を複数ラベル分類タスクとして扱うことを提案した。
2) 複数ラベル天候分類タスクに対してCNN-RNNアーキテクチャを提示した。これは、特徴抽出のためのCNN、特徴応答を再較正するチャネル方向アテンションモデル、異なる天候ラベル間の関係性をモデル化する畳み込みLSTMから構成される。
3) 新たな複数ラベル天候分類データセットを構築し、加えて一時的属性データセット [19] を天候認識タスク向けに変換した。データセットはプロジェクトWebサイトで公開予定である。

### 1.3. 構成

本論文の残りは以下のように構成する。第2節では天候認識に関する関連研究を概観する。第3節では提案手法を詳細に述べる。第4節ではまず、新しい複数ラベル天候画像データセットの構築と、一時的属性データセット [19] の改変について述べ、その後、両データセットにおける実験結果を分析する。第5節で本論文を結論づける。

---

## 2. 関連研究

本論文では天候認識の研究を大きく2つに分類する。1つは手作り特徴（hand-crafted features）の設計に焦点を当てるもの、もう1つはCNNを用いて天候認識を行うものである。

### 2.1. 手作り特徴による天候認識

多くの運転支援システムは道路の安全性向上のために天候認識を利用する。例えば、極端な天候条件下で速度制限を設定したり、雨天時に自動的にワイパーを作動させるなどである。これらの研究では手作り特徴が一般的に用いられている。Kurihata ら [12, 24] は雨滴が雨天の強い手がかりであると提案し、フロントガラス上の雨滴を検出する雨特徴を開発した。Roser ら [15] は複数の関心領域（ROI）を定義し、雨天認識のために様々なヒストグラム特徴を開発した。Yan ら [13] は勾配振幅ヒストグラム、HSVカラーヒストグラム、道路情報を用いて、晴・曇・雨の分類を行った。さらに、霧の検出に特化した手法もいくつか提案されている。Hautière ら [14] はKoschmiederの法則 [25] を用いて霧の存在を検出し、視程を推定した。Bronte ら [26] はSobelベースの晴/霧検出、エッジ二値化、Hough直線検出、消失点検出、道路/空のセグメンテーションなど多数の技術を用いた。Gallen ら [27] は夜間の霧検出に注目し、車両のヘッドライトや街灯の周囲に生じる背散乱ベールやハローを検出した。Pavli ら [28, 16] は画像を周波数領域へ変換し、パワースペクトルにおいて様々なスケールと方向のGaborフィルタを学習して霧の存在を検出した。これらの手法は良好な性能を示すが、多くは車載視点に限定され、より広範な応用には適用しづらい。

一般的な屋外画像からの天候認識に取り組んだ研究もある。Li ら [29] はフォトメトリックステレオに基づく手法を提案し、特定地点の天候条件を推定した。Zhao ら [9] は、動的天候（雨、雪など）では画素ごとの輝度が時間とともに変動し、静的天候（晴、霧など）ではほとんど変化しないことを指摘した。彼らはまず動的と静的を区別し、その後さらに複数の時空間および色彩特徴を用いて天候カテゴリを推定する二段階分類スキームを提案した。[17] では、屈曲点情報、パワースペクトル勾配、エッジ勾配エネルギー、彩度、コントラスト、画像ノイズなどのグローバル特徴を抽出して天候分類を行った。Li ら [18] も [17] のいくつかの特徴を用い、特徴の距離に基づく決定木を構築した。[1] では、2クラス天候認識のために反射、影、空の記述子など複数の天候手がかりを提案した。さらに、テスト画像に近い投票者により大きな重みを与える協調学習戦略を採用した。Zhang ら [30, 20] は、晴、雨、雪、霞の各天候クラスに個別の特徴と、2つのグローバル特徴を提案した。加えて、これらの特徴を融合するためにmultiple kernel learning を導入した [30]。また [31] では、短いビデオクリップにおける空間的外観と時間的ダイナミクスの両方を調べ、いくつかの天候タイプを認識した。

このように多くの工夫を凝らした特徴が設計されてきたが、それらの多くは特定の視点や天候クラスに限定され、広範な応用には適用しづらい。

### 2.2. CNNによる天候認識

近年、CNNは画像分類 [32]、物体検出 [33]、セマンティックセグメンテーション [34] など様々なコンピュータビジョンタスクで圧倒的な性能を示している。AlexNet [32]、VGGNet [35]、ResNet [36] などの優れたCNNアーキテクチャが提案され、従来手法を大きく上回った。CNNの成功に触発され、天候認識へCNNを適用する試みもいくつか行われた。Elhoseiny ら [3] はAlexNet [32] を2クラス天候分類データセット [1] で微調整し、より良い結果を得た。Lu ら [2] は手作りの天候特徴とCNN特徴を組み合わせ、分類性能をさらに改善した。しかし [2] で議論されるように、天候クラス間には明確な境界が存在しない。複数の天候状態が同時に現れることもある。したがって、天候認識を単一ラベル分類問題として扱うと、情報が失われる。Li ら [37] は天候手がかりの補助的なセマンティックセグメンテーションを用い、天候状態を包括的に記述することを提案した。この戦略は情報損失を軽減できるが、セグメンテーションマスクは人にとって直観的ではない。

---

## 3. 提案手法

天候状態を包括的に記述するために、本研究では天候認識を複数ラベル分類問題として扱う。さらに、複数ラベル分類を段階的な予測として定式化するCNN-RNNモデルを開発する。図3は提案アーキテクチャの概略を示す。主に3つの部分（基本CNN、チャネル方向アテンションモデル、畳み込みLSTM）から構成される。CNNは屋外画像から初期特徴を抽出する。具体的にはVGGNet [35] の最初の5つの畳み込み/プーリング群を用いる。チャネル方向アテンションモデルはチャネルごとのアテンション重みを適応的に計算し、特徴応答を再較正する。畳み込みLSTMは、視覚特徴と隠れ状態を用いて天候ラベルを1つずつ予測し、内部メモリ状態にコンテキスト情報を保持することで、ラベル間の共起依存性を暗黙にモデル化する。

### 3.1. CNN-RNNアーキテクチャにおける畳み込みLSTM

近年、RNN、特にLSTMは、画像/動画キャプショニング [38] やニューラル機械翻訳 [39] などの系列モデリングで成功を収めている。一般性を失わずに、LSTMは以下のように定式化できる [40]。

```
i_t = σ(W_iw x_t + U_ih h_{t-1} + b_i),
f_t = σ(W_fw x_t + U_fh h_{t-1} + b_f),
o_t = σ(W_ow x_t + U_oh h_{t-1} + b_o),
g_t = tanh(W_gw x_t + U_gh h_{t-1} + b_g),
c_t = f_t ◦ c_{t-1} + i_t ◦ g_t,
h_t = o_t ◦ tanh(c_t),
(1)
```

ここで、添字 t はLSTMの t 番目のステップを示す。x_t は入力データ、h_t は隠れ状態、c_t はセル状態。i_t, f_t, o_t はそれぞれ入力ゲート、忘却ゲート、出力ゲート。W, U, b は学習すべき重みとバイアス。σ, tanh, ◦ はそれぞれシグモイド関数、双曲線正接関数、要素ごとの積を表す。式(1)が示すように、各ステップで x_t と前の隠れ状態 h_{t-1} を入力として取り、h_t に履歴情報を記録することで時間的依存性を活用する。

標準LSTMは系列モデリングに強力だが、画像処理では空間情報が無視されがちである [23]。式(1)から分かるように、状態間と入力-状態間の変換には全結合が用いられる。一般に入力画像 x_t ∈ R^{W×H×C} はLSTMに入力する前に1次元ベクトルに平坦化され、この過程で空間情報が失われる。これを克服するため、本研究では畳み込みLSTM [23] を採用する。これは次のように定式化される。

```
i_t = σ(W_iw ⊗ x_t + U_ih ⊗ h_{t-1} + b_i),
f_t = σ(W_fw ⊗ x_t + U_fh ⊗ h_{t-1} + b_f),
o_t = σ(W_ow ⊗ x_t + U_oh ⊗ h_{t-1} + b_o),
g_t = tanh(W_gw ⊗ x_t + U_gh ⊗ h_{t-1} + b_g),
c_t = f_t ◦ c_{t-1} + i_t ◦ g_t,
h_t = o_t ◦ tanh(c_t),
(2)
```

ここで ⊗ は畳み込み演算。他の記号は式(1)と同じである。畳み込みLSTMでは、入力特徴 x_t、セル状態 c_t、隠れ状態 h_t、ゲート i_t, f_t, o_t は全て3次元テンソルであり、状態間・入力-状態間の変換に畳み込みが用いられる。したがって、特徴の空間情報が保持される。さらに、畳み込み演算は暗黙の空間アテンション機構を有し、ターゲットラベルに対応する領域はより高い活性応答を示す傾向がある。実験では、畳み込みLSTMが天候ラベル予測のための重要領域に注意を払うこと、また空間アテンションの有無にかかわらず一般的なLSTMより良好な結果をもたらすことを確認した。

### 3.2. CNN-RNNアーキテクチャにおけるチャネル方向アテンションモデル

通常、異なるチャネルの特徴マップでは異なる領域が活性化し、また、天候ラベルの推定時に画像領域ごとの重要度は異なる。本アーキテクチャでは、畳み込みLSTMの各ステップで1つの天候ラベルを予測する。Squeeze-and-Excitationに着想を得て [41]、我々はチャネル方向のアテンションモデルを提案し、ラベル予測時に特徴応答を適応的に再較正する。図4にモデルの概略を示す。

[41] で議論されているように、グローバル情報の活用は特徴工学で一般的である。各チャネルのアテンション重みを計算するため、我々は同様の戦略を採用し、グローバル平均プーリングによってチャネルごとの統計量を生成する。これはチャネル方向のグローバル空間情報の記述子と見なせる。ただし本研究の複数ラベル天候分類では、直前に予測したラベルに応じてチャネル方向アテンション重みを適応的に得たい。そのため、畳み込みLSTMの隠れ状態に符号化されたチャネル方向統計量も考慮する。2種の統計情報は以下のように表される。

```
a_k = f_a(x_k) = (1 / (W×H)) * Σ_{i=1..W} Σ_{j=1..H} x_k(i,j),        (3)
d_k = f_a(h_{t-1,k}) = (1 / (W×H)) * Σ_{i=1..W} Σ_{j=1..H} h_{t-1,k}(i,j),  (4)
```

ここで x_k と h_{t-1,k} はそれぞれ k 番目チャネルの視覚特徴と畳み込みLSTMの前ステップ隠れ状態。f_a はグローバル平均プーリング、a_k と d_k は視覚特徴と隠れ状態における k 番目チャネルの統計情報。W,H は特徴の幅と高さ。なお本手法では、視覚特徴と隠れ状態の次元は一致している。

統計情報を得た後、チャネル方向アテンション重みは以下で計算する。

```
z_k = σ( w2 · δ( w1 · [a_k, d_k] + b1 ) + b2 ),                         (5)
```

ここで w, b は学習パラメータ、δ はReLU [42]、[·,·] は連結、σ はシグモイドで重みを0〜1に正規化する。最終的に再較正された特徴は、元の特徴をアテンション重みでスケーリングして得られる。

```
x̃ = Σ_{k=1..C} z_k · x_k.                                               (6)
```

### 3.3. 推論

本論文では、天候ラベルは固定の順序で予測する。実際には、他のラベルの順序は共起関係に基づいて設定する。詳細は4.2節に示す。

畳み込みLSTMの各ステップで、3D隠れ状態を1Dベクトルに平坦化し、天候ラベルを予測する。

```
p_t = σ(w_p · h_t + b_p),                                               (7)
```

ここで p_t ∈ [0,1] は t 番目の天候ラベルの出力確率、h_t は平坦化した隠れ状態、w_p と b_p は学習パラメータ。

各ステップの損失は以下で与えられる。

```
loss_t = -(1/N) Σ_{i=1..N} [ p_{i,t} log p̃_{i,t} + (1 - p_{i,t}) log(1 - p̃_{i,t}) ],  (8)
```

ここで N は学習サンプル数、p_{i,t} は i 番目サンプルの t 番目天候クラスに対する真のラベル、p̃_{i,t} は対応する予測ラベル。総損失は次式である。

```
Loss = Σ_{t=1..T} loss_t,                                               (9)
```

T は全天候クラス数。

### 3.4. 学習詳細

提案手法はTensorFlowで実装した。収束を加速するため、2段階の学習戦略を採用した。第1段階では、基本CNN（VGGNet [35] の最初の5つの畳み込み/プーリング群）を学習する。具体的には、出力層を T ニューロン（Tは天候クラス数）に置換し、複数ラベルのシグモイド交差エントロピー損失で学習する。ImageNet ILSVRCで事前学習したVGGNetを微調整に用いる。第2段階では、VGGNetの全結合層を除去し、その他のパラメータを固定する。そのうえで、CNNの抽出特徴に基づき、畳み込みLSTMとチャネル方向アテンションモデルをゼロから学習する。この段階ではXavier初期化を用いる。最適化にはAdam [43] を用い、一段・二段のモーメントはそれぞれ0.9と0.999に設定する。過学習を避けるため、両段階の全結合層の後にDropout [44] を適用し、すべての重みにL2正則化を導入する。Dropout率は0.5、L2正則化係数は0.0005とした。学習率は0.0001で初期化し、損失が安定したら10分の1に下げる。また、第2段階後に基本CNNのパラメータ固定を解除して全体を微調整することも試したが、性能向上は見られなかった。

学習前に各サンプルを256×256にリサイズし、左右反転・ランダムクロップ・ランダムノイズでデータ拡張を行った。ミニバッチ確率的学習を採用し、各エポック前に画像をシャッフルし、バッチサイズ50で学習する。提案アーキテクチャの主要コンポーネント形状の詳細は表1に示す。バイアスの形状は容易に推測できる。

```
表1: 提案CNN-RNNアーキテクチャの詳細
Name                        channel-wise attention model  ConvLSTM      convolution kernel  w1        w2
Shape                       14×14×512                     14×14×512     3×3                 1024×512  512×512
```

---

## 4. 実験

本研究が初めて天候認識を複数ラベル分類として扱うため、既存のデータセットは存在しない。そこで、提案手法の評価のために、1つは一時的属性データセット [19] の改変版、もう1つは新規に収集した2つのデータセットを構築した。本節では、まず2つのデータセットの構築手順と詳細を述べる。次に、天候ラベル間の共起関係を探索する。最後に、評価指標、比較手法、実験結果を順に示す。

### 4.1. データセットの記述

#### 4.1.1. 一時的属性データセット（変換版）

第1のデータセットは、元々屋外シーンの理解と編集のために構築された一時的属性データセット [19] を天候認識向けに変換したものである。このデータセットは天候認識専用ではないが、魅力的な性質を持つ。第一に、画像は山、都市、町、都市景観など多様な屋外シーンを跨いで撮影されている。スケールや視点も多様で、シーン間の多様性が高い。第二に、同一シーンの様々な外観を示すように画像が精選されている。さらに [19] の著者らは40の一時的属性（天候関連属性：’sunny’, ’rain’, ’fog’ など）を定義している。各画像に対して、天候関連属性は排他的ではなく注釈付けされており、これは我々の複数ラベル天候認識実験に重要である。図5にいくつかの例を示す。

天候認識のために、40属性のうち6つの天候関連属性（’sunny’, ’cloudy’, ’fog’, ’snow’, ’moist’, ’rain’）を選択し、その他は無視した。また、全ての天候属性強度が非常に低い例が少数存在することを確認した。その一部は夜明けや夕暮れに撮影され、他はどの天候カテゴリにも明確な特徴を示さない。そこで、すべての属性強度が0.5未満の例を表す ’other’ クラスを追加した。0.5未満は、注釈者がその属性が画像に表れていないと判断したことを意味する。本研究では、天候認識タスクにおいて属性が0.5以上を1、未満を0に設定した。最終的に、このデータセットは7つの天候クラスと合計8571枚の画像を含む。詳細統計は表2に示す。

#### 4.1.2. 複数ラベル天候分類データセット（新規）

提案手法をさらに評価するため、5つの天候クラス（’sunny’, ’cloudy’, ’foggy’, ’rainy’, ’snowy’）からなる1万枚の画像を新たに収集した。すべてインターネットから精選した。既存データセットと比較すると、次の利点がある。第一に、多くの既存データセットが2〜3クラスに限定されるのに対し、本データセットは日常で一般的な天候条件を網羅している。第二に、都市、村、都市部など多様なシーンを含み（図6）、スケールや視点も多様である。第三に、ラベルは相互排他的ではなく、より多くの天候情報を提供する。

注釈はクラウドソーシングで実施した。注釈者は非排他的に天候属性強度（0〜1、0.5がしきい値）を判定した。0.5未満は、その天候と判定できない（属性が含まれていても）ことを示す。各画像は少なくとも5名で注釈し、各属性強度の平均値を採用した。注釈の有効性を担保するため、各属性強度の分散も計算し、分散が閾値を超える場合は議論により再判定した。最終的に、0.5以上を1、未満を0としてラベルを生成した。

図7は2つのデータセットにおけるラベル分布を示す。詳細統計は表2にある。両データセットとも、’cloudy’ のサンプル数が多い。これは曇が他の天候としばしば共起するためである。曇を除くと、新規データセットの方がよりバランスが良い。また表2から、両データセットとも半数以上のサンプルが複数ラベルを持つことが分かり、天候認識を複数ラベル分類として扱う妥当性を裏付ける。

```
図7: 2つのデータセットにおける天候ラベル分布
(a) 一時的属性データセット、(b) 複数ラベル天候分類データセット
```

```
表2: 構築データセットの統計
Datasets                     Sunny Cloudy Foggy Snowy Moist Rainy Other  >1 label  Total
Transient attribute dataset  2637  4113   1224  2120  4295  424   1148   4471      8571
Multi-label weather dataset  2370  7474   2737  2052  –     2212  –      5763      10000
```

### 4.2. 共起関係

1枚の画像に複数の天候が同時に現れ得ることを定性的に述べたが、次式に従って異なる天候条件間の共起関係を定量的にも分析した。

```
R(i, j) = ( Σ_Ω conc(i, j) ) / ( Σ_Ω I(i) ),                             (10)
```

ここで i, j は天候条件、R(i,j) は i と j の共起度、Ω はデータセットの全サンプル集合。conc(i,j) と I(i) は次で定義されるインジケータ関数。

```
conc(i, j) = { 1, if Arr(i) ≥ 0.5 ∧ Arr(j) ≥ 0.5
               0, otherwise                                           }   (11)

I(i)       = { 1, if Arr(i) ≥ 0.5
               0, otherwise                                           }   (12)
```

Arr(i) は天候 i の属性強度、∧ は論理積。式(10)は、天候 i の出現回数に対する i と j の共起回数の比を表す。したがって、Σ_j R(i,j) と Σ_j R(j,i) はそれぞれラベル i の他ラベルへの影響度と依存度を表す。依存性を活用してラベルを予測するには、最も影響力の大きいラベルを最初に、依存的なラベルを最後に予測するのが自然である。これに基づき、次式でラベルの順位付けを行う。

```
r = ( Σ_j R(i, j) ) / ( Σ_j R(j, i) ).                                    (13)
```

r が大きいラベルほど上位に位置づけられる。

図8に解析結果を示す。直観に一致して、雨と曇、雪と霧など、異なる天候条件間の強い共起が見られる。これらのサンプルはしばしばカテゴリ境界近傍にある。本研究では、ラベルの組み合わせでそれらを表現する。第二に、天候認識タスクではラベル依存性が確かに存在し、複数ラベル予測時に考慮が必要である。本研究では畳み込みLSTMを用いて依存性を捉え、段階的に予測する。式(13)に従い、一時的属性データセットではラベル順序を

- moist → cloudy → others → sunny → snowy → foggy → rainy

新規データセットでは

- cloudy → sunny → foggy → rainy → snowy

と固定した。実際には他の順序も試し、性能は概ね同等で、上記が多くの場面で最良であった。

### 4.3. 評価指標と比較手法

まず、クラス単位の適合率（precision）と再現率（recall）を評価指標とする。クラス単位とは特定の天候ラベルについて、そのラベルが正しく予測されれば正解とみなす。これから平均適合率（AP）と平均再現率（AR）を算出する（クラス単位の平均）。

加えて、サンプル単位の指標として全体適合率（OP）と全体再現率（OR）も用いる。

```
OP = ( Σ_{n=1..N} Σ_{i=1..K} f(p_{n,i}, p̃_{n,i}) ) / (N·K),              (14)
OR = ( Σ_{n=1..N} Σ_{i=1..K} f(p_{n,i}, p̃_{n,i}) ) / ( Σ_{n=1..N} Σ_{i=1..K} p_{n,i} ), (15)
```

N はサンプル数、K はクラス数、p_{n,i} と p̃_{n,i} は n 番目サンプルの i 番目クラスに対する真/予測ラベル。f(·) は次のインジケータ関数。

```
f(p, p̃) = { 1, if p = p̃
             0, otherwise }                                               (16)
```

最後に、F1スコア（クラス平均AF1、サンプル平均OF1）を、適合率と再現率の調和平均として算出する。

比較手法として、複数ラベル版のAlexNet [32] とVGGNet [35] を用いる。さらに、提案する畳み込みLSTMとチャネル方向アテンションの有効性検証のため、いくつかのCNN-RNN構成（CNN-LSTM、空間アテンション付きCNN-LSTM（CLA）、空間アテンション付きCNN-GRU（CGA）、チャネルアテンションなしのCNN-ConvLSTM）とも比較する。一般的な複数ラベル学習法であるML-KNN [45] と ML-ARAM [46] も比較に含める。ML-KNNはKNNを複数ラベルに拡張した遅延学習法、ML-ARAMはAdaptive Resonance Associative Mapを複数ラベル分類へ拡張したもの。実験ではscikit-multilearnの実装を用いた。公平性のため、全てのCNN-RNN構成は提案法と同じVGGNetを特徴抽出器として用いる。ML-KNNとML-ARAMに入力する特徴も、各データセットで事前学習したVGGNetの最終全結合層の出力を用いる。提案法をCNN-Att-ConvLSTMと呼ぶ。

### 4.4. 一時的属性データセットでの結果

一時的属性データセットでは、1000枚をテスト、1000枚を検証、残りを学習に用いた。結果を表3に示す。CNN-Att-ConvLSTMはOP, OR, OF1で最良を達成し、AP, AR, AF1でもSOTAと同等の結果を示した。空間アテンション付きCNN-LSTM（CLA）も良好だが、空間アテンションなしのCNN-LSTMは性能が大きく劣化し、天候認識における重要領域の重要性を示す。CNN-GRU+空間アテンション（CGA）はCLAとほぼ同等であった。CNN-ConvLSTMもCLAと類似の結果を得ており、重要領域の情報抽出における畳み込みLSTMの有効性を示す。総じて、提案法は複数ラベル版AlexNet/VGGNet、ML-KNN/ML-ARAM、その他のCNN-RNN手法より優れており、提案手法の優越性が示された。

クラス別では ’rainy’ と ’other’ で性能が低い。これは本データセットの多くの画像が遠景で、雨天の特徴の検出が難しいためである。また ’other’ のサンプルは非常に少なく、晴や曇に誤分類されやすい。

```
表3: 一時的属性データセットでの実験結果（クラス別: precision/recall）
Approach               Sunny       Cloudy      Foggy       Snowy       Moist       Rainy       Other       AP     AR     AF1     OP     OR     OF1
AlexNet [32]           0.756/0.892 0.802/0.868 0.688/0.688 0.948/0.803 0.840/0.903 0.625/0.392 0.789/0.224 0.7783 0.6815 0.7267 0.8967 0.7999 0.8455
VGGNet [35]            0.777/0.836 0.847/0.803 0.767/0.717 0.848/0.920 0.873/0.899 0.880/0.431 0.622/0.552 0.8022 0.7369 0.7682 0.9043 0.8155 0.8576
CNN-LSTM               0.819/0.754 0.883/0.555 0.777/0.529 0.654/0.205 0.986/0.142 0.271/0.373 0.000/0.000 0.6271 0.3653 0.4617 0.7991 0.3814 0.5163
CLA                    0.856/0.816 0.882/0.786 0.861/0.63  0.945/0.9   0.883/0.913 0.596/0.608 0.547/0.657 0.7958 0.7585 0.7767 0.9117 0.8150 0.8606
CGA                    0.765/0.895 0.861/0.805 0.879/0.63  0.949/0.892 0.891/0.901 0.632/0.471 0.573/0.56  0.7925 0.7362 0.7633 0.9093 0.8176 0.8610
CNN-ConvLSTM           0.868/0.777 0.876/0.813 0.789/0.703 0.938/0.916 0.867/0.929 0.653/0.627 0.548/0.552 0.7913 0.7596 0.7751 0.9120 0.8203 0.8637
ML-KNN [45]            0.720/0.892 0.898/0.742 0.866/0.609 0.887/0.944 0.818/0.933 0.700/0.412 0.663/0.425 0.7927 0.7080 0.7479 0.9001 0.8037 0.8492
ML-ARAM [46]           0.790/0.826 0.784/0.853 0.903/0.609 0.968/0.855 0.938/0.842 0.889/0.314 0.550/0.739 0.8318 0.7197 0.7717 0.9044 0.8047 0.8517
CNN-Att-ConvLSTM       0.857/0.785 0.851/0.852 0.837/0.682 0.952/0.896 0.913/0.911 0.656/0.454 0.585/0.628 0.8091 0.7428 0.7760 0.9167 0.8231 0.8678
```

### 4.5. 複数ラベル天候分類データセットでの結果

新規データセットでは、2000枚をテスト、1000枚を検証、残りを学習に用いた。表4に示すように、CNN-Att-ConvLSTMはほぼ全評価指標で最良となり、提案手法の有効性を再び示した。

```
表4: 複数ラベル天候分類データセットでの実験結果（クラス別: precision/recall）
Approach               Sunny       Cloudy      Foggy       Rainy       Snowy       AP     AR     AF1     OP     OR     OF1
AlexNet [32]           0.84/0.74   0.896/0.942 0.735/0.89  0.784/0.685 0.876/0.905 0.8263 0.8325 0.8294 0.9007 0.8668 0.8834
VGGNet [35]            0.772/0.851 0.927/0.915 0.867/0.728 0.814/0.701 0.887/0.931 0.8533 0.8252 0.8390 0.9087 0.8494 0.8780
CNN-LSTM               0.843/0.791 0.897/0.958 0.86/0.73   0.83/0.694  0.94/0.556  0.8739 0.7458 0.8048 0.8991 0.8127 0.8537
CLA                    0.853/0.791 0.908/0.944 0.863/0.772 0.856/0.687 0.924/0.924 0.8809 0.8237 0.8513 0.9169 0.8582 0.8866
CGA                    0.858/0.785 0.901/0.954 0.825/0.802 0.829/0.729 0.924/0.924 0.8671 0.8387 0.8527 0.9161 0.8722 0.8936
CNN-ConvLSTM           0.855/0.78  0.899/0.953 0.798/0.862 0.843/0.716 0.926/0.924 0.8643 0.8472 0.8557 0.9165 0.8793 0.8975
ML-KNN [45]            0.837/0.724 0.912/0.94  0.819/0.834 0.794/0.736 0.918/0.934 0.8562 0.8336 0.8447 0.9138 0.8766 0.8948
ML-ARAM [46]           0.772/0.81  0.853/0.936 0.952/0.783 0.641/0.762 0.979/0.84  0.8397 0.8262 0.8330 0.8988 0.8650 0.8816
CNN-Att-ConvLSTM       0.838/0.843 0.917/0.953 0.856/0.861 0.856/0.758 0.894/0.938 0.8721 0.8702 0.8705 0.9263 0.8946 0.9135
```

図9にいくつかの認識例を示す。VGGNetベースの複数ラベル分類をベースラインとし、提案法の活性化マップとアテンション重みを比較する。提案法は、ラベル予測時に最も関連の強い天候手がかりに注意を向けられる一方、VGGNetは誤って地面を強く活性化して雨と誤判定するなどの失敗がある。提案法も、注釈が曖昧（晴と曇の中間）であったり、手がかりが明瞭でない場合（濡れた路面が目立たない）には失敗することがある。視覚特徴のみに基づいているため、湿度など他モダリティ情報を併用すれば改善が見込まれる。

---

## 5. 結論

単一画像に複数の天候条件が同時に現れ得ることを踏まえ、天候認識を単一ラベル分類として扱う欠点を分析し、複数ラベル分類フレームワークを提案した。本手法は、画像が複数の天候カテゴリに属し得ることを許容し、天候状態をより包括的に記述できる。具体的には、CNNをチャネル方向アテンションで拡張して最も関連の強い視覚特徴を抽出し、畳み込みLSTMで空間情報を保持しつつ天候ラベルを段階的に予測するCNN-RNNアーキテクチャである。さらに、学習データ不足を補うため、2つのデータセットを構築した。実験結果は提案手法の有効性を検証した。

将来の課題として、天候認識に分布予測 [47, 48, 49, 50] を導入し、複数ラベル分類に加えて各天候クラスの強度（確率分布）を予測することで、天候状態をより包括的に記述することを計画している。また、湿度や気温など他モダリティの情報活用も検討する。

---

## 参考文献

[1]  C. Lu, D. Lin, J. Jia, C.-K. Tang, Two-class weather classification, in: Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition, CVPR ’14, 2014, pp. 3718–3725.

[2]  C. Lu, D. Lin, J. Jia, C. K. Tang, Two-class weather classification, IEEE Transactions on Pattern Analysis and Machine Intelligence 39 (12) (2017) 2510–2524.

[3]  M. Elhoseiny, S. Huang, A. Elgammal, Weather classification with deep convolutional neural networks, in: Image Processing (ICIP), 2015 IEEE International Conference on, 2015, pp. 3349–3353.

[4]  J. Han, D. Zhang, G. Cheng, N. Liu, D. Xu, Advanced deep-learning techniques for salient and category-specific object detection: a survey, IEEE Signal Processing Magazine 35 (1) (2018) 84–100.

[5]  J. Han, R. Quan, D. Zhang, F. Nie, Robust object co-segmentation using background prior, IEEE Transactions on Image Processing 27 (4) (2018) 1639–1651.

[6]  G. Cheng, C. Yang, X. Yao, L. Guo, J. Han, When deep learning meets metric learning: remote sensing image scene classification via learning discriminative cnns, IEEE transactions on geoscience and remote sensing 56 (5) (2018) 2811–2821.

[7]  J. Han, G. Cheng, Z. Li, D. Zhang, A unified metric learning-based framework for co-saliency detection, IEEE Transactions on Circuits and Systems for Video Technology, 2017.

[8]  A. Qayyum, S. M. Anwar, M. Awais, M. Majid, Medical image retrieval using deep convolutional neural network, Neurocomputing 266 (2017) 8–20.

[9]  X. Zhao, P. Liu, J. Liu, X. Tang, A time, space and color-based classification of different weather conditions, in: Visual Communications and Image Processing (VCIP), 2011 IEEE, 2011, pp. 1–4.

[10]  S. Shah, J. K. Aggarwal, Mobile robot navigation and scene modeling using stereo fish-eye lens system, Mach. Vision Appl. 10 (4) (1997) 159–173.

[11]  H. Katsura, J. Miura, M. Hild, Y. Shirai, A view-based outdoor navigation using object recognition robust to changes of weather and seasons, in: Intelligent Robots and Systems). Proceedings. 2003 IEEE/RSJ International Conference on, Vol. 3, 2003, pp. 2974–2979.

[12]  H. Kurihata, T. Takahashi, I. Ide, Y. Mekada, H. Murase, Y. Tamatsu, T. Miyahara, Rainy weather recognition from in-vehicle camera images for driver assistance, in: IEEE Proceedings. Intelligent Vehicles Symposium, 2005, pp. 205–210.

[13]  X. Yan, Y. Luo, X. Zheng, Weather recognition based on images captured by vision system in vehicle, in: Proceedings of the 6th International Symposium on Neural Networks: Advances in Neural Networks - Part III, ISNN 2009, Springer-Verlag, 2009, pp. 390–398.

[14]  N. Hautière, J.-P. Tarel, J. Lavenant, D. Aubert, Automatic fog detection and estimation of visibility distance through use of an onboard camera, Machine Vision and Applications 17 (1) (2006) 8–20.

[15]  M. Roser, F. Moosmann, Classification of weather situations on single color images, in: Intelligent Vehicles Symposium, 2008 IEEE, 2008, pp. 798–803.

[16]  M. Pavlic, G. Rigoll, S. Ilic, Classification of images in fog and fog-free scenes for use in vehicles, in: 2013 IEEE Intelligent Vehicles Symposium (IV), Gold Coast City, Australia, June 23-26, 2013, 2013, pp. 481–486.

[17]  H. Song, Y. Chen, Y. Gao, Weather Condition Recognition Based on Feature Extraction and K-NN, Springer Berlin Heidelberg, 2014, pp. 199–210.

[18]  Q. Li, Y. Kong, S. m. Xia, A method of weather recognition based on outdoor images, in: Computer Vision Theory and Applications (VISAPP), 2014 International Conference on, Vol. 2, 2014, pp. 510–516.

[19]  P.-Y. Laffont, Z. Ren, X. Tao, C. Qian, J. Hays, Transient attributes for high-level understanding and editing of outdoor scenes, ACM Transactions on Graphics (proceedings of SIGGRAPH) 33 (4).

[20]  Z. Zhang, H. Ma, H. Fu, C. Zhang, Scene-free multi-class weather classification on single images, Neurocomputing 207 (2016) 365 – 373.

[21]  H. Chen, G. Ding, S. Zhao, J. Han, Temporal-difference learning with sampling baseline for image captioning, in: Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, 2018.

[22]  M. Chen, G. Ding, S. Zhao, H. Chen, Q. Liu, J. Han, Reference based LSTM for image captioning, in: Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, 2017, pp. 3981–3987.

[23]  X. Shi, Z. Chen, H. Wang, D. Yeung, W. Wong, W. Woo, Convolutional LSTM network: A machine learning approach for precipitation nowcasting, in: Advances in Neural Information Processing Systems, 2015, pp. 802–810.

[24]  H. Kurihata, T. Takahashi, Y. Mekada, I. Ide, H. Murase, Y. Tamatsu, T. Miyahara, Raindrop detection from in-vehicle video camera images for rainfall judgment, in: First International Conference on Innovative Computing, Information and Control - Volume I (ICICIC’06), Vol. 2, 2006, pp. 544–547.

[25]  W. E. K. Middleton, Vision through the Atmosphere, 1957, pp. 254–287.

[26]  S. Bronte, L. M. Bergasa, P. F. Alcantarilla, Fog detection system based on computer vision techniques, in: 2009 12th International IEEE Conference on Intelligent Transportation Systems, 2009, pp. 1–6.

[27]  R. Gallen, A. Cord, N. Hautire, D. Aubert, Towards night fog detection through use of in-vehicle multipurpose cameras, in: Intelligent Vehicles Symposium (IV), 2011 IEEE, 2011, pp. 399–404.

[28]  M. Pavli, H. Belzner, G. Rigoll, S. Ili, Image based fog detection in vehicles, in: Intelligent Vehicles Symposium (IV), 2012 IEEE, 2012, pp. 1132–1137.

[29]  L. Shen, P. Tan, Photometric stereo and weather estimation using internet images, in: Computer Vision and Pattern Recognition, IEEE Conference on, 2009, pp. 1850–1857.

[30]  Z. Zhang, H. Ma, Multi-class weather classification on single images, in: Image Processing (ICIP), 2015 IEEE International Conference on, 2015, pp. 4396–4400.

[31]  K. G. Derpanis, M. Lecce, K. Daniilidis, R. P. Wildes, Dynamic scene understanding: The role of orientation features in space and time in scene classification, in: 2012 IEEE Conference on Computer Vision and Pattern Recognition, 2012, pp. 1306–1313.

[32]  A. Krizhevsky, I. Sutskever, G. E. Hinton, Imagenet classification with deep convolutional neural networks, in: Advances in Neural Information Processing Systems 25, 2012, pp. 1097–1105.

[33]  S. Ren, K. He, R. Girshick, J. Sun, Faster R-CNN: Towards real-time object detection with region proposal networks, in: Advances in Neural Information Processing Systems (NIPS), 2015.

[34]  K. He, G. Gkioxari, P. Dollr, R. Girshick, Mask r-cnn, in: 2017 IEEE International Conference on Computer Vision (ICCV), 2017, pp. 2980–2988.

[35]  K. Simonyan, A. Zisserman, Very deep convolutional networks for large-scale image recognition, CoRR abs/1409.1556.

[36]  K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition, in: 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp. 770–778.

[37]  X. Li, Z. Wang, X. Lu, A multi-task framework for weather recognition, in: Proceedings of the 2017 ACM on Multimedia Conference, MM 2017, Mountain View, CA, USA, October 23-27, 2017, 2017, pp. 1318–1326.

[38]  X. L. Xuelong Li, Bin Zhao, Mam-rnn: Multi-level attention model based rnn for video captioning, in: Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI-17, 2017, pp. 2208–2214.

[39]  D. Britz, A. Goldie, M. Luong, Q. V. Le, Massive exploration of neural machine translation architectures, CoRR abs/1703.03906.

[40]  S. Hochreiter, J. Schmidhuber, Long short-term memory, Neural computation 9 (8) (1997) 1735–1780.

[41]  J. Hu, L. Shen, G. Sun, Squeeze-and-excitation networks, arXiv preprint arXiv:1709.01507.

[42]  V. Nair, G. E. Hinton, Rectified linear units improve restricted boltzmann machines, in: Proceedings of the 27th International Conference on Machine Learning, 2010, pp. 807–814.

[43]  D. P. Kingma, J. Ba, Adam: A method for stochastic optimization, CoRR abs/1412.6980.

[44]  N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, R. Salakhutdinov, Dropout: A simple way to prevent neural networks from overfitting, Journal of Machine Learning Research 15 (2014) 1929–1958.

[45]  Ml-knn: A lazy learning approach to multi-label learning, Pattern Recognition 40 (7) (2007) 2038 – 2048.

[46]  F. Benites, E. P. Sapozhnikova, HARAM: A hierarchical ARAM neural network for large-scale text classification, in: IEEE International Conference on Data Mining Workshop, ICDMW 2015, Atlantic City, NJ, USA, November 14-17, 2015, 2015, pp. 847–854.

[47]  S. Zhao, G. Ding, Y. Gao, J. Han, Approximating discrete probability distribution of image emotions by multi-modal features fusion, in: Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, 2017, pp. 4669–4675.

[48]  S. Zhao, G. Ding, Y. Gao, J. Han, Learning visual emotion distributions via multi-modal features fusion, in: Proceedings of the 2017 ACM on Multimedia Conference, 2017, pp. 369–377.

[49]  S. Zhao, G. Ding, Y. Gao, X. Zhao, Y. Tang, J. Han, H. Yao, Q. Huang, Discrete probability distribution prediction of image emotions with shared sparse learning, IEEE Transactions on Affective Computing (1) (2018) 1–1.

[50]  S. Zhao, H. Yao, Y. Gao, R. Ji, G. Ding, Continuous probability distribution prediction of image emotions via multitask shared sparse regression, IEEE Transactions on Multimedia 19 (3) (2017) 632–645.
