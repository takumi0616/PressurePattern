import sys
from pathlib import Path
import multiprocessing
import os
import datetime
import random
import traceback
from functools import partial
from tqdm import tqdm
import re
import numpy as np
import pandas as pd
import xarray as xr
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import japanize_matplotlib
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from sklearn.decomposition import PCA
from sklearn.metrics import adjusted_rand_score, confusion_matrix, balanced_accuracy_score
from scipy.optimize import linear_sum_assignment

try:
    from acs import ACS
    print("ACS class (acs.py) imported successfully.")
except ImportError as e:
    print(f"Error: acs.py ã‹ã‚‰ACSã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")
    print("ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã« acs.py ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã—ã¦ãã ã•ã„ã€‚")
    sys.exit(1)

GLOBAL_SEED = 17
os.environ['PYTHONHASHSEED'] = str(GLOBAL_SEED)
np.random.seed(GLOBAL_SEED)
random.seed(GLOBAL_SEED)
timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
output_dir_base = Path("./result_prmsl_acs_random_search_v3")
output_dir = output_dir_base / f"run_{timestamp}"
trial_logs_dir = output_dir / "trial_logs"
os.makedirs(output_dir, exist_ok=True)
os.makedirs(trial_logs_dir, exist_ok=True)
log_file_path = output_dir / f"main_log_{timestamp}.txt"

class Logger:
    """æ¨™æº–å‡ºåŠ›ã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã¨ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸¡æ–¹ã¸ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚"""
    def __init__(self, filename="Default.log"):
        self.terminal = sys.stdout
        self.log_file_handle = open(filename, "a", encoding="utf-8")
    def write(self, message):
        self.terminal.write(message)
        self.log_file_handle.write(message)
        self.log_file_handle.flush()
    def flush(self):
        self.terminal.flush()
        self.log_file_handle.flush()
    def close(self):
        if self.log_file_handle and not self.log_file_handle.closed:
            self.log_file_handle.close()

def get_sorted_indices(sort_method, valid_times, random_seed=None):
    """
    NumPyã®ã¿ã‚’ä½¿ç”¨ã—ãŸé«˜é€Ÿã‚½ãƒ¼ãƒˆï¼ˆæ±ºå®šçš„ãªå‹•ä½œã‚’ä¿è¨¼ï¼‰
    """
    n_samples = len(valid_times)
    indices = np.arange(n_samples)
    if sort_method in ['normal_sort', 'change_normal_sort']:
        return indices[np.argsort(valid_times)]
    elif sort_method in ['month_sort', 'change_month_sort']:
        times_dt = valid_times.astype('datetime64[D]') # NumPyã®datetime64å‹ã®æ“ä½œã‚’ç›´æ¥ä½¿ç”¨ï¼ˆé«˜é€ŸåŒ–ï¼‰
        times_M = valid_times.astype('datetime64[M]') # æœˆã¨å¹´ã‚’åŠ¹ç‡çš„ã«æŠ½å‡º
        times_Y = valid_times.astype('datetime64[Y]')
        months = ((times_M - times_Y) / np.timedelta64(1, 'M')).astype(int) # æœˆã‚’0-11ã®æ•´æ•°ã¨ã—ã¦å–å¾—
        years = times_Y.astype(int) + 1970  # å¹´ã‚’æ•´æ•°ã¨ã—ã¦å–å¾— Unix epoch ã‹ã‚‰ã®å¹´æ•°
        sort_keys = np.lexsort((valid_times, years, months)) # è¤‡åˆã‚­ãƒ¼ã§ã®ã‚½ãƒ¼ãƒˆï¼ˆæœˆâ†’å¹´â†’æ—¥æ™‚ã®é †ï¼‰lexsortã¯å³ã‹ã‚‰å·¦ã®é †åºã§ã‚½ãƒ¼ãƒˆã™ã‚‹ã®ã§ã€é€†é †ã§æŒ‡å®š
        return indices[sort_keys]
    else:
        if random_seed is not None: # ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã®å ´åˆã¯ã€ã‚·ãƒ¼ãƒ‰ã‚’æ˜ç¤ºçš„ã«è¨­å®š
            rng = np.random.RandomState(random_seed)
            rng.shuffle(indices)
        else:
            raise ValueError(f"Unknown sort method: {sort_method}") # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å‹•ä½œã‚’é¿ã‘ã€ã‚¨ãƒ©ãƒ¼ã‚’ç™ºç”Ÿã•ã›ã‚‹
        return indices

def calculate_composite_score(cluster_report, n_true_clusters, ideal_cluster_range=(1.0, 2.0)):
    """
    ã‚¯ãƒ©ã‚¹ã‚¿ç´”åº¦ã¨ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã‹ã‚‰è¤‡åˆè©•ä¾¡ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã™ã‚‹ã€‚
    """
    if cluster_report.empty or 'n_samples' not in cluster_report.columns or cluster_report['n_samples'].sum() == 0:
        return 0.0, 0.0, 0.0

    total_samples = cluster_report['n_samples'].sum()
    weighted_purity = np.sum(cluster_report['purity'] * cluster_report['n_samples']) / total_samples
    n_clusters = len(cluster_report)
    min_ideal_clusters = n_true_clusters * ideal_cluster_range[0]
    max_ideal_clusters = n_true_clusters * ideal_cluster_range[1]
    center_ideal_clusters = (min_ideal_clusters + max_ideal_clusters) / 2.0
    if min_ideal_clusters <= n_clusters <= max_ideal_clusters:
        penalty = 1.0
    else:
        distance_from_center = abs(n_clusters - center_ideal_clusters)
        scale = n_true_clusters
        penalty = np.exp(-distance_from_center / scale)

    final_score = weighted_purity * penalty
    return final_score, weighted_purity, penalty

def calculate_all_metrics_multi_label(preds, y_true_multi, label_encoder):
    """
    æœ€é©åŒ–ç‰ˆï¼šNumPyé…åˆ—æ“ä½œã‚’æ´»ç”¨ã—ãŸé«˜é€ŸåŒ–
    """
    n_samples = len(preds)
    base_labels = label_encoder.classes_
    n_base_labels = len(base_labels)
    unique_pred_clusters = np.unique(preds[preds != -1])# NumPyé…åˆ—ã¨ã—ã¦å‡¦ç†
    n_pred_clusters = len(unique_pred_clusters)
    if n_pred_clusters == 0:
        return {
            'composite_score': 0.0, 'weighted_purity': 0.0, 'accuracy': 0.0,
            'bacc': 0.0, 'ari': 0.0, 'n_clusters': 0,
            'pred_map': {}, 'cm': np.zeros((n_base_labels, n_base_labels), dtype=int),
            'cluster_report': pd.DataFrame()
        }
    
    contingency_np = np.zeros((n_pred_clusters, n_base_labels), dtype=int)# NumPyé…åˆ—ã§ã‚³ãƒ³ãƒ†ã‚£ãƒ³ã‚¸ã‚§ãƒ³ã‚·ãƒ¼è¡Œåˆ—ã‚’ä½œæˆï¼ˆé«˜é€ŸåŒ–ï¼‰
    cluster_to_idx = {cluster: idx for idx, cluster in enumerate(unique_pred_clusters)}
    valid_mask = preds != -1 # ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸå‡¦ç†
    valid_preds = preds[valid_mask]
    valid_true_multi = [y_true_multi[i] for i in range(n_samples) if valid_mask[i]]
    for i, pred_cluster in enumerate(valid_preds):
        cluster_idx = cluster_to_idx[pred_cluster]
        for true_idx in valid_true_multi[i]:
            if true_idx != -1:
                contingency_np[cluster_idx, true_idx] += 1
    
    row_ind, col_ind = linear_sum_assignment(-contingency_np) # ãƒãƒ³ã‚¬ãƒªã‚¢ãƒ³æ³•ã«ã‚ˆã‚‹äºˆæ¸¬ã‚¯ãƒ©ã‚¹ã‚¿ã¨çœŸãƒ©ãƒ™ãƒ«ã®ãƒãƒƒãƒ”ãƒ³ã‚°
    pred_map = {unique_pred_clusters[pred_i]: true_i for pred_i, true_i in zip(row_ind, col_ind)}
    correct_hits_for_accuracy = 0 # ä»¥é™ã®å‡¦ç†ã‚‚NumPyé…åˆ—ã§åŠ¹ç‡åŒ–
    y_true_for_bacc_cm = []
    y_pred_for_bacc_cm = []
    cluster_report_list = []
    for idx, pred_cluster_id in enumerate(unique_pred_clusters): # ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®çµ±è¨ˆã‚’ä¸€æ‹¬è¨ˆç®—
        cluster_mask = preds == pred_cluster_id
        n_samples_in_cluster = np.sum(cluster_mask)
        
        if n_samples_in_cluster == 0:
            continue
            
        correct_in_cluster = 0
        dominant_label_name = "Unmapped"
        if pred_cluster_id in pred_map:
            mapped_label_idx = pred_map[pred_cluster_id]
            dominant_label_name = base_labels[mapped_label_idx]
            cluster_indices = np.where(cluster_mask)[0] # ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸæ­£è§£åˆ¤å®š
            for i in cluster_indices:
                if mapped_label_idx in y_true_multi[i]:
                    correct_in_cluster += 1
        
        purity = correct_in_cluster / n_samples_in_cluster
        cluster_report_list.append({
            'cluster_id': pred_cluster_id,
            'n_samples': n_samples_in_cluster,
            'purity': purity,
            'dominant_label': dominant_label_name
        })
    
    for i in range(n_samples): # BAcc ã¨ Confusion Matrix ã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ˆåŠ¹ç‡åŒ–ï¼‰
        pred_cluster = preds[i]
        if pred_cluster == -1:
            continue
            
        true_label_indices = y_true_multi[i]
        if pred_cluster in pred_map:
            mapped_label_idx = pred_map[pred_cluster]
            y_pred_for_bacc_cm.append(mapped_label_idx)
            
            if mapped_label_idx in true_label_indices:
                correct_hits_for_accuracy += 1
                y_true_for_bacc_cm.append(mapped_label_idx)
            else:
                y_true_for_bacc_cm.append(true_label_indices[0])
    
    accuracy = correct_hits_for_accuracy / n_samples if n_samples > 0 else 0.0 # å„è©•ä¾¡æŒ‡æ¨™ã®æœ€çµ‚è¨ˆç®—
    bacc = balanced_accuracy_score(y_true_for_bacc_cm, y_pred_for_bacc_cm) if y_true_for_bacc_cm else 0.0
    cm = confusion_matrix(y_true_for_bacc_cm, y_pred_for_bacc_cm, labels=np.arange(n_base_labels)) if y_true_for_bacc_cm else np.zeros((n_base_labels, n_base_labels))
    y_true_representative = [t[0] for t in y_true_multi]
    ari = adjusted_rand_score(y_true_representative, preds)
    cluster_report_df = pd.DataFrame(cluster_report_list)
    composite_score, weighted_purity, _ = calculate_composite_score(cluster_report_df, n_base_labels)
    return {
        'composite_score': composite_score,
        'weighted_purity': weighted_purity,
        'accuracy': accuracy,
        'bacc': bacc,
        'ari': ari,
        'n_clusters': n_pred_clusters,
        'pred_map': pred_map,
        'cm': cm,
        'cluster_report': cluster_report_df
    }

def run_acs_trial(param_values_tuple_with_trial_info,
                  fixed_params_dict,
                  pca_data_dict,
                  y_data_multi,
                  sin_time_data,
                  cos_time_data,
                  n_true_cls_worker,
                  trial_log_dir_path,
                  label_encoder_worker,
                  valid_times_worker):
    """
    ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒã®1è©¦è¡Œã‚’ç‹¬ç«‹ã—ã¦å®Ÿè¡Œã™ã‚‹ã€‚
    æŒ‡å®šã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿æŠ•å…¥é †åºã§å­¦ç¿’ã—ã€ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«å…¨æŒ‡æ¨™ã‚’è¨ˆç®—ã—ã€å…¨å±¥æ­´ã‚’è¿”ã™ã€‚
    """
    (trial_count, params_combo), trial_specific_seed = param_values_tuple_with_trial_info
    worker_log_path = trial_log_dir_path / f"trial_{trial_count}.log"
    original_stdout, original_stderr = sys.stdout, sys.stderr
    acs_model_trial = None # å¤‰æ•°ã‚’é–¢æ•°ã®ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã§åˆæœŸåŒ–
    result = {
        'params_combo': {},
        'history': [],
        'event_log': [],
        'error_traceback': 'Initialization failed',
        'duration_seconds': 0,
        'acs_random_state_used': trial_specific_seed,
        'trial_count_from_worker': trial_count
    }
    trial_start_time = datetime.datetime.now()
    try:
        with open(worker_log_path, 'w', encoding='utf-8') as log_file:
            sys.stdout = sys.stderr = log_file
            data_input_order = params_combo.get('data_input_order')
            pca_n_components = params_combo.get('pca_n_components')
            include_time_features = params_combo.get('include_time_features')
            num_epochs_worker = params_combo.get('num_epochs')
            activation_type_worker = params_combo.get('activation_type')
            result['params_combo'] = params_combo.copy() # resultã«ã¯å…ƒã®å®Œå…¨ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¿å­˜
            result['error_traceback'] = None
            X_pca = pca_data_dict[pca_n_components] # ç‰¹å¾´é‡æ§‹ç¯‰
            X_features = np.hstack([X_pca, sin_time_data, cos_time_data]) if include_time_features else X_pca
            X_scaled_data = MinMaxScaler().fit_transform(X_features).astype(np.float64)
            n_features_worker = X_scaled_data.shape[1]
            params_for_acs = params_combo.copy()
            keys_to_remove_for_acs = [
                'data_input_order', 'pca_n_components', 'include_time_features', 'num_epochs'
            ]
            for key in keys_to_remove_for_acs:
                params_for_acs.pop(key, None)

            current_run_params = {
                **fixed_params_dict, 
                'n_features': n_features_worker, 
                'random_state': trial_specific_seed,
                **params_for_acs
            }
            print(f"\n--- [Worker] ãƒˆãƒ©ã‚¤ã‚¢ãƒ« {trial_count} é–‹å§‹ ---")
            print(f"[Worker {trial_count}] ãƒ‡ãƒ¼ã‚¿æŠ•å…¥é †åº: {data_input_order}")
            print(f"[Worker {trial_count}] ç‰¹å¾´é‡: PCA={pca_n_components}, Time={include_time_features}, Total Dim={n_features_worker}")
            print(f"[Worker {trial_count}] ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: { {k: f'{v:.4f}' if isinstance(v, float) else v for k, v in params_combo.items()} }")
            np.random.seed(trial_specific_seed) # ä¹±æ•°çŠ¶æ…‹ã‚’æ˜ç¤ºçš„ã«è¨­å®šï¼ˆãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹å†…ï¼‰
            random.seed(trial_specific_seed)
            acs_model_trial = ACS(**current_run_params) # ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã¨å­¦ç¿’
            initial_indices = get_sorted_indices(data_input_order, valid_times_worker, random_seed=trial_specific_seed)
            for epoch in range(1, num_epochs_worker + 1):
                current_indices = initial_indices
                if 'change' in data_input_order and epoch % 2 == 0:
                    current_indices = initial_indices[::-1]

                for data_idx in current_indices:
                    U_p = X_scaled_data[data_idx, :]
                    acs_model_trial.partial_fit(U_p, epoch=epoch, data_idx=int(data_idx))

                preds = acs_model_trial.predict(X_scaled_data)
                epoch_metrics = calculate_all_metrics_multi_label(preds, y_data_multi, label_encoder_worker)
                epoch_metrics['epoch'] = epoch
                result['history'].append(epoch_metrics)
                print(f"[Worker {trial_count}] Epoch {epoch}/{num_epochs_worker} - Cls: {epoch_metrics['n_clusters']}, "
                      f"Score: {epoch_metrics['composite_score']:.4f}, BAcc: {epoch_metrics['bacc']:.4f}, Acc: {epoch_metrics['accuracy']:.4f}")

    except Exception: # ã©ã®æ®µéšã§ã‚¨ãƒ©ãƒ¼ãŒèµ·ãã¦ã‚‚ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚’è¨˜éŒ²
        result['error_traceback'] = traceback.format_exc()
        if 'log_file' in locals() and not log_file.closed: # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã¾ã é–‹ã„ã¦ã„ã‚‹å ´åˆã¯æ›¸ãè¾¼ã‚€
             print(f"--- [Worker] ãƒˆãƒ©ã‚¤ã‚¢ãƒ« {trial_count} ã§è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ ---\n{result['error_traceback']}", file=log_file)

    finally: # æœ€å¾Œã«å¿…ãšå®Ÿè¡Œã•ã‚Œã‚‹å¾Œå‡¦ç†
        result['duration_seconds'] = (datetime.datetime.now() - trial_start_time).total_seconds()
        if acs_model_trial is not None:
            result['event_log'] = acs_model_trial.event_log

        sys.stdout = original_stdout
        sys.stderr = original_stderr
        print(f"--- [Worker] ãƒˆãƒ©ã‚¤ã‚¢ãƒ« {trial_count} çµ‚äº† | Time: {result['duration_seconds']:.2f}s | ã‚¨ãƒ©ãƒ¼: {'ã‚ã‚Š' if result['error_traceback'] else 'ãªã—'} ---")

        return result
        
def sample_random_params(param_dist, rng=None):
    """ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒã®ãŸã‚ã«ã€å®šç¾©ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç¯„å›²ã‹ã‚‰å€¤ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ã€‚"""
    if rng is None:
        rng = random.Random()
    
    params = {}
    params['activation_type'] = rng.choice(param_dist['activation_type']) # ã¾ãšã€activation_typeã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
    
    for key, value in param_dist.items():
        if key == 'activation_type': # activation_type ã¯æ—¢ã«å‡¦ç†æ¸ˆã¿ãªã®ã§ã‚¹ã‚­ãƒƒãƒ—
            continue
        if params['activation_type'] == 'circular' and key in ['initial_lambda_vector_val', 'initial_lambda_crossterm_val']: # activation_typeã«å¿œã˜ã¦ä¸è¦ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãªã„
            continue
        if params['activation_type'] == 'elliptical' and key == 'initial_lambda_scalar':
            continue
        if isinstance(value, list): # æ—¢å­˜ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯
            params[key] = rng.choice(value)
        elif isinstance(value, tuple) and len(value) == 2:
            if all(isinstance(v, int) for v in value):
                params[key] = rng.randint(value[0], value[1])
            else:
                params[key] = round(rng.uniform(value[0], value[1]), 4)
    return params

def plot_energy_contour_for_epoch(model, epoch, save_path,
                                  X_scaled_data_for_eval, X_pca_visual, y_true_multi,
                                  label_encoder, pca_visual_model):
    """æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®çŠ¶æ…‹ã§ã‚¨ãƒãƒ«ã‚®ãƒ¼ç­‰é«˜ç·šãƒ—ãƒ­ãƒƒãƒˆç­‰ã‚’ç”Ÿæˆã—ä¿å­˜ã™ã‚‹ (è¤‡åˆãƒ©ãƒ™ãƒ«å¯¾å¿œãƒ»æ”¹è‰¯ç‰ˆ)ã€‚"""
    n_base_labels = len(label_encoder.classes_)
    current_clusters = model.M

    if current_clusters > 0: # --- è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®— (è¤‡åˆãƒ©ãƒ™ãƒ«å¯¾å¿œ) ---
        preds = model.predict(X_scaled_data_for_eval)
        metrics = calculate_all_metrics_multi_label(preds, y_true_multi, label_encoder) # å¤‰æ›´ç‚¹: 'cluster_report' ã‚’å«ã‚€ metrics ã‚’å—ã‘å–ã‚‹
    else: # ã‚¯ãƒ©ã‚¹ã‚¿ãŒå­˜åœ¨ã—ãªã„å ´åˆ
        metrics = {
            'composite_score': 0.0, 'weighted_purity': 0.0, 'accuracy': 0.0,
            'bacc': 0.0, 'ari': 0.0, 'n_clusters': 0, 'cm': np.zeros((n_base_labels, n_base_labels)),
            'cluster_report': pd.DataFrame()
        }

    fig = plt.figure(figsize=(24, 8), constrained_layout=True)
    gs = gridspec.GridSpec(1, 3, figure=fig, width_ratios=[1.8, 1, 1.2])
    ax_contour, ax_info, ax_cm = fig.add_subplot(gs[0, 0]), fig.add_subplot(gs[0, 1]), fig.add_subplot(gs[0, 2])
    fig.suptitle(f'ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çŠ¶æ…‹ã¨è©•ä¾¡ (Epoch: {epoch})', fontsize=20)
    distinguishable_colors = [
        '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',
        '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf',
        '#aec7e8', '#ffbb78', '#98df8a', '#ff9896', '#c5b0d5'
    ]
    palette_true_labels = distinguishable_colors[:n_base_labels]
    # --- å·¦ãƒ‘ãƒãƒ«: ã‚¨ãƒãƒ«ã‚®ãƒ¼ç­‰é«˜ç·šã¨ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœ ---
    x_min, x_max = X_pca_visual[:, 0].min() - 0.1, X_pca_visual[:, 0].max() + 0.1
    y_min, y_max = X_pca_visual[:, 1].min() - 0.1, X_pca_visual[:, 1].max() + 0.1
    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 80), np.linspace(y_min, y_max, 80))
    grid_points_2d = np.c_[xx.ravel(), yy.ravel()]
    try:
        grid_points_high_dim = pca_visual_model.inverse_transform(grid_points_2d)
        energy_values = np.array([model.calculate_energy_at_point(p) for p in grid_points_high_dim])
        Z_grid = energy_values.reshape(xx.shape)
        contour = ax_contour.contourf(xx, yy, Z_grid, levels=20, cmap='viridis', alpha=0.5)
        fig.colorbar(contour, ax=ax_contour, label='ã‚¨ãƒãƒ«ã‚®ãƒ¼ (E)')
    except Exception as e:
        ax_contour.text(0.5, 0.5, f"ã‚¨ãƒãƒ«ã‚®ãƒ¼è¨ˆç®—/æç”»ã‚¨ãƒ©ãƒ¼:\n{e}", ha='center', va='center')

    y_true_main_labels = [label_encoder.classes_[l[0]] for l in y_true_multi]
    sns.scatterplot(ax=ax_contour, x=X_pca_visual[:, 0], y=X_pca_visual[:, 1],
                    hue=y_true_main_labels, hue_order=label_encoder.classes_,
                    palette=palette_true_labels, s=50, alpha=0.7, edgecolor='w', linewidth=0.5, legend='full')
    ax_contour.legend(title="True Label (Main)", bbox_to_anchor=(1.05, 1), loc='upper left')
    if current_clusters > 0 and not metrics['cluster_report'].empty:
        try:
            all_centers_2d = pca_visual_model.transform(model.get_cluster_centers())
            cluster_report_df = metrics['cluster_report']
            label_to_color = {label: color for label, color in zip(label_encoder.classes_, palette_true_labels)}

            for _, row in cluster_report_df.iterrows():
                cluster_id = int(row['cluster_id'])
                dominant_label_name = row['dominant_label']
                
                if cluster_id < len(all_centers_2d):
                    center_2d = all_centers_2d[cluster_id]
                    text_color = label_to_color.get(dominant_label_name, 'black')

                    ax_contour.text(center_2d[0], center_2d[1], str(cluster_id),
                                    color=text_color,
                                    fontsize=12,
                                    fontweight='bold',
                                    ha='center',
                                    va='center',
                                    bbox=dict(boxstyle='circle,pad=0.3', fc='white', ec=text_color, alpha=0.8, lw=1.5))
        except Exception as e:
            print(f"Epoch {epoch}: ã‚¯ãƒ©ã‚¹ã‚¿ä¸­å¿ƒã®æç”»ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

    ax_contour.set_title('ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœ (PCA 2D)', fontsize=16)
    ax_contour.set_xlabel('ä¸»æˆåˆ†1'); ax_contour.set_ylabel('ä¸»æˆåˆ†2')
    # --- ä¸­å¤®ãƒ‘ãƒãƒ«: æƒ…å ±è¡¨ç¤º ---
    ax_info.axis('off')
    ax_info.set_title('Learning Status Summary', fontsize=16)
    info_text = (
        f"Epoch: {epoch}\n"
        f"Clusters (M): {metrics['n_clusters']}\n\n"
        f"Composite Score: {metrics['composite_score']:.4f}\n"
        f"Weighted Purity: {metrics['weighted_purity']:.4f}\n\n"
        f"Accuracy: {metrics['accuracy']:.4f}\n"
        f"Balanced Accuracy: {metrics['bacc']:.4f}\n"
        f"Adjusted Rand Index: {metrics['ari']:.4f}"
    )
    ax_info.text(0.05, 0.95, info_text, transform=ax_info.transAxes, fontsize=12,
                 verticalalignment='top', bbox=dict(boxstyle='round,pad=0.5', fc='aliceblue', alpha=0.9),
                 family='monospace')
    # --- å³ãƒ‘ãƒãƒ«: æ··åŒè¡Œåˆ— ---
    sns.heatmap(metrics['cm'], annot=True, fmt="d", cmap="Blues",
                xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_,
                ax=ax_cm, cbar=False)
    ax_cm.set_title('Confusion Matrix (after mapping)', fontsize=16)
    ax_cm.set_xlabel("Predicted Label (mapped)"); ax_cm.set_ylabel("True Label")
    plt.setp(ax_cm.get_xticklabels(), rotation=45, ha="right")
    plt.savefig(save_path / f"epoch_{epoch:04d}.png", dpi=150, bbox_inches='tight')
    plt.close(fig)

def plot_cluster_composition(final_preds, y_true_multi, label_encoder, save_path, metric_name, trial_id):
    """
    å„ã‚¯ãƒ©ã‚¹ã‚¿ã®ãƒ©ãƒ™ãƒ«æ§‹æˆç‡ã‚’ç¤ºã™ç©ã¿ä¸Šã’æ£’ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆãƒ»ä¿å­˜ã™ã‚‹ã€‚
    """
    # --- 0. æº–å‚™ ---
    base_labels = label_encoder.classes_
    n_base_labels = len(base_labels)
    unique_clusters = sorted([p for p in np.unique(final_preds) if p != -1]) # -1ï¼ˆæœªåˆ†é¡ï¼‰ã‚’é™¤å¤–ã—ã€å®Ÿéš›ã«ãƒ‡ãƒ¼ã‚¿ãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚ŒãŸã‚¯ãƒ©ã‚¹ã‚¿ã®ã¿ã‚’å¯¾è±¡ã¨ã™ã‚‹
    if not unique_clusters:
        print(f"[{metric_name.upper()}] æœ‰åŠ¹ãªã‚¯ãƒ©ã‚¹ã‚¿ãŒäºˆæ¸¬ã•ã‚Œãªã‹ã£ãŸãŸã‚ã€æ§‹æˆãƒ—ãƒ­ãƒƒãƒˆã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return

    composition_df = pd.DataFrame(0, index=unique_clusters, columns=base_labels) # --- 1. ãƒ‡ãƒ¼ã‚¿é›†è¨ˆç”¨ã®DataFrameã‚’ä½œæˆ ---
    for i in range(len(final_preds)): # --- 2. å„ã‚µãƒ³ãƒ—ãƒ«ã®æ‰€å±ã‚¯ãƒ©ã‚¹ã‚¿ã¨çœŸãƒ©ãƒ™ãƒ«ã‚’ã‚«ã‚¦ãƒ³ãƒˆ ---
        pred_cluster = final_preds[i]
        if pred_cluster == -1:
            continue

        true_indices = y_true_multi[i]
        for true_idx in true_indices:
            if true_idx != -1: # ãƒ€ãƒŸãƒ¼ãƒ©ãƒ™ãƒ«(-1)ã¯ç„¡è¦–
                true_label_name = base_labels[true_idx]
                composition_df.loc[pred_cluster, true_label_name] += 1

    cluster_totals = composition_df.sum(axis=1) # --- 3. ã‚«ã‚¦ãƒ³ãƒˆã‚’å‰²åˆã«å¤‰æ› ---    
    proportion_df = composition_df.divide(cluster_totals.replace(0, 1), axis=0) # ã‚¼ãƒ­é™¤ç®—ã‚’é¿ã‘ã‚‹ãŸã‚ã€åˆè¨ˆãŒ0ã®ã‚¯ãƒ©ã‚¹ã‚¿ã¯1ã§å‰²ã‚‹ï¼ˆçµæœã¯0ã®ã¾ã¾ï¼‰
    # --- 4. ãƒ—ãƒ­ãƒƒãƒˆ ---
    distinguishable_colors = [
        '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',
        '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf',
        '#aec7e8', '#ffbb78', '#98df8a', '#ff9896', '#c5b0d5'
    ] # ä»–ã®ãƒ—ãƒ­ãƒƒãƒˆã¨è‰²ã‚’åˆã‚ã›ã‚‹
    palette = distinguishable_colors[:n_base_labels]
    fig, ax = plt.subplots(figsize=(max(12, len(unique_clusters) * 0.5), 8))
    proportion_df.plot(kind='bar', stacked=True, ax=ax, color=palette, width=0.8,
                       edgecolor='white', linewidth=0.5)
    # --- 5. æ•´å½¢ ---
    ax.set_title(f'ã‚¯ãƒ©ã‚¹ã‚¿æ§‹æˆã®å‰²åˆ (Trial {trial_id}, åŸºæº–: {metric_name.upper()})', fontsize=16)
    ax.set_xlabel('ã‚¯ãƒ©ã‚¹ã‚¿ç•ªå· (Cluster ID)', fontsize=12)
    ax.set_ylabel('ãƒ©ãƒ™ãƒ«ã®å‰²åˆ (Proportion of Labels)', fontsize=12)
    ax.yaxis.grid(True, linestyle='--', alpha=0.6)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=0)
    ax.legend(title='True Label', bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=10)
    for i, (cluster_id, total) in enumerate(zip(unique_clusters, cluster_totals)): # å„ã‚¯ãƒ©ã‚¹ã‚¿ã®ç·ã‚µãƒ³ãƒ—ãƒ«æ•°ã¨æœ€ã‚‚å¤šã„True Labelã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
        cluster_row = composition_df.loc[cluster_id] # æœ€ã‚‚å¤šã„True Labelã‚’è¦‹ã¤ã‘ã‚‹
        dominant_label = cluster_row.idxmax() if cluster_row.sum() > 0 else 'None'
        ax.text(i, 1.01, f'n={total}\n({dominant_label})', 
                ha='center', va='bottom', fontsize=9, 
                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8)) # n=æ•°ã¨dominant labelã‚’è¡¨ç¤º

    plt.tight_layout(rect=[0, 0, 0.88, 1]) # å‡¡ä¾‹ãŒåã¾ã‚‹ã‚ˆã†ã«èª¿æ•´
    save_filename = save_path / f"cluster_composition_{metric_name}.png" # --- 6. ä¿å­˜ ---
    plt.savefig(save_filename, dpi=200, bbox_inches='tight')
    plt.close(fig)
    print(f"âœ… ã‚¯ãƒ©ã‚¹ã‚¿æ§‹æˆã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {save_filename.resolve()}")

def plot_cluster_counts(final_preds, y_true_multi, label_encoder, save_path, metric_name, trial_id):
    """
    å„ã‚¯ãƒ©ã‚¹ã‚¿ã®ãƒ©ãƒ™ãƒ«æ§‹æˆã€Œæ•°ã€ã‚’ç¤ºã™ç©ã¿ä¸Šã’æ£’ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆãƒ»ä¿å­˜ã™ã‚‹ã€‚
    """
    # --- 0. æº–å‚™ ---
    base_labels = label_encoder.classes_
    n_base_labels = len(base_labels)
    unique_clusters = sorted([p for p in np.unique(final_preds) if p != -1])
    if not unique_clusters:
        print(f"[{metric_name.upper()}] æœ‰åŠ¹ãªã‚¯ãƒ©ã‚¹ã‚¿ãŒäºˆæ¸¬ã•ã‚Œãªã‹ã£ãŸãŸã‚ã€æ§‹æˆæ•°ãƒ—ãƒ­ãƒƒãƒˆã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return

    # --- 1. ãƒ‡ãƒ¼ã‚¿é›†è¨ˆç”¨ã®DataFrameã‚’ä½œæˆ (å‰²åˆã‚°ãƒ©ãƒ•ã¨å…±é€š) ---
    composition_df = pd.DataFrame(0, index=unique_clusters, columns=base_labels)
    for i in range(len(final_preds)):
        pred_cluster = final_preds[i]
        if pred_cluster == -1:
            continue
        
        true_indices = y_true_multi[i]
        for true_idx in true_indices:
            if true_idx != -1:
                true_label_name = base_labels[true_idx]
                composition_df.loc[pred_cluster, true_label_name] += 1
    
    # --- 2. ãƒ—ãƒ­ãƒƒãƒˆ (ğŸ’¡å‰²åˆã«å¤‰æ›ã›ãšã€ç”Ÿã®ã‚«ã‚¦ãƒ³ãƒˆæ•°ã‚’ä½¿ç”¨) ---
    distinguishable_colors = [
        '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',
        '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf',
        '#aec7e8', '#ffbb78', '#98df8a', '#ff9896', '#c5b0d5'
    ]
    palette = distinguishable_colors[:n_base_labels]
    fig, ax = plt.subplots(figsize=(max(12, len(unique_clusters) * 0.5), 8))
    composition_df.plot(kind='bar', stacked=True, ax=ax, color=palette, width=0.8,
                        edgecolor='white', linewidth=0.5) # composition_df (ç”Ÿã®ã‚«ã‚¦ãƒ³ãƒˆæ•°) ã‚’ç›´æ¥ãƒ—ãƒ­ãƒƒãƒˆ
    # --- 3. æ•´å½¢ ---
    ax.set_title(f'ã‚¯ãƒ©ã‚¹ã‚¿æ§‹æˆã®ã‚µãƒ³ãƒ—ãƒ«æ•° (Trial {trial_id}, åŸºæº–: {metric_name.upper()})', fontsize=16)
    ax.set_xlabel('ã‚¯ãƒ©ã‚¹ã‚¿ç•ªå· (Cluster ID)', fontsize=12)
    ax.set_ylabel('ã‚µãƒ³ãƒ—ãƒ«æ•° (Number of Samples)', fontsize=12) # Yè»¸ãƒ©ãƒ™ãƒ«ã‚’å¤‰æ›´
    ax.yaxis.grid(True, linestyle='--', alpha=0.6)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=0)
    ax.legend(title='True Label', bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=10)
    cluster_totals = composition_df.sum(axis=1) # å„ã‚¯ãƒ©ã‚¹ã‚¿ã®ç·ã‚µãƒ³ãƒ—ãƒ«æ•°ã¨æœ€ã‚‚å¤šã„True Labelã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
    for i, (cluster_id, total) in enumerate(zip(unique_clusters, cluster_totals)):
        cluster_row = composition_df.loc[cluster_id] # æœ€ã‚‚å¤šã„True Labelã‚’è¦‹ã¤ã‘ã‚‹
        dominant_label = cluster_row.idxmax() if cluster_row.sum() > 0 else 'None'
        ax.text(i, total, f'n={total}\n({dominant_label})', 
                ha='center', va='bottom', fontsize=9, color='black',
                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8)) # n=æ•°ã¨dominant labelã‚’è¡¨ç¤º

    plt.tight_layout(rect=[0, 0, 0.88, 1])
    save_filename = save_path / f"cluster_counts_{metric_name}.png" # --- 4. ä¿å­˜ ---
    plt.savefig(save_filename, dpi=200, bbox_inches='tight')
    plt.close(fig)
    print(f"âœ… ã‚¯ãƒ©ã‚¹ã‚¿æ§‹æˆæ•°ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {save_filename.resolve()}")

def main_process_logic():
    """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã€å‰å‡¦ç†ã€ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒã€3åŸºæº–ã§ã®çµæœè©•ä¾¡ã€ãƒ—ãƒ­ãƒƒãƒˆã¾ã§ã‚’çµ±æ‹¬ã™ã‚‹ã€‚"""
    os.environ['PYTHONHASHSEED'] = str(GLOBAL_SEED)
    os.environ['OMP_NUM_THREADS'] = '1'
    os.environ['MKL_NUM_THREADS'] = '1'
    os.environ['NUMEXPR_NUM_THREADS'] = '1'
    np.random.seed(GLOBAL_SEED)
    random.seed(GLOBAL_SEED)
    sys.stdout = sys.stderr = Logger(log_file_path)
    print("=" * 80)
    print("ACSãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹æ°—åœ§é…ç½®ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ•™å¸«ãªã—ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚° (è¤‡åˆãƒ©ãƒ™ãƒ«ãƒ»è¤‡æ•°æŒ‡æ¨™å¯¾å¿œç‰ˆ)")
    print("=" * 80)
    print("\n--- 1. ãƒ‡ãƒ¼ã‚¿æº–å‚™ ---")
    pca_dims_to_test = [15, 20, 25]
    preprocessed_data_cache_file = Path("./preprocessed_prmsl_data_all_labels.pkl")
    if preprocessed_data_cache_file.exists():
        print(f"âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã™...")
        data_cache = pd.read_pickle(preprocessed_data_cache_file)
        precalculated_pca_data, y_true_multi, sin_time, cos_time, label_encoder, n_samples, valid_times, base_labels, all_labels_str = (
        data_cache['precalculated_pca_data'], data_cache['y_true_multi'], data_cache['sin_time'],
        data_cache['cos_time'], data_cache['label_encoder'], data_cache['n_samples'],
        data_cache['valid_times'], data_cache['base_labels'], data_cache['all_labels_str']
)
    else:
        print(f"âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒãªã„ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ã‚’æ–°è¦ç”Ÿæˆã—ã¾ã™...")
        ds = xr.open_dataset("./prmsl_era5_all_data.nc")
        ds_period = ds.sel(valid_time=slice('1991-01-01', '2000-12-31'))
        ds_filtered = ds_period
        base_labels = ['1', '2A', '2B', '2C', '2D', '3A', '3B', '3C', '3D', '4A', '4B', '5', '6A', '6B', '6C']
        label_encoder = LabelEncoder().fit(base_labels)
        all_labels_str = ds_filtered['label'].values
        y_true_multi = []
        for label_str in all_labels_str:
            parts = set(re.split(r'[+-]', label_str))# '+' ã¾ãŸã¯ '-' ã§ãƒ©ãƒ™ãƒ«ã‚’åˆ†å‰²ã—ã€ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒ‘ãƒ¼ãƒ„ã‚’å–å¾—ã€‚å„ãƒ‘ãƒ¼ãƒ„ã‚’åŸºæœ¬ãƒ©ãƒ™ãƒ«ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å¤‰æ›ï¼ˆå­˜åœ¨ã—ãªã„ã‚‚ã®ã¯ç„¡è¦–ï¼‰
            valid_indices = [label_encoder.transform([p])[0] for p in parts if p in label_encoder.classes_]
            if not valid_indices:
                valid_indices = [-1] # ä¸‡ãŒä¸€ã€ã©ã®åŸºæœ¬ãƒ©ãƒ™ãƒ«ã«ã‚‚ä¸€è‡´ã—ãªã„å ´åˆã¯ã€ãƒ€ãƒŸãƒ¼ã¨ã—ã¦-1ã‚’è¿½åŠ 
            y_true_multi.append(tuple(sorted(valid_indices)))

        n_samples = ds_filtered.sizes['valid_time']
        valid_times = ds_filtered['valid_time'].values
        msl_flat = ds_filtered['msl'].values.reshape(n_samples, -1)
        sin_time, cos_time = ds_filtered['sin_time'].values.reshape(-1, 1), ds_filtered['cos_time'].values.reshape(-1, 1)
        msl_flat_scaled = MinMaxScaler().fit_transform(msl_flat)
        precalculated_pca_data = {n: PCA(n_components=n, random_state=GLOBAL_SEED).fit_transform(msl_flat_scaled) for n in pca_dims_to_test}
        data_to_cache = {
            'precalculated_pca_data': precalculated_pca_data, 'y_true_multi': y_true_multi, 'sin_time': sin_time,
            'cos_time': cos_time, 'label_encoder': label_encoder, 'n_samples': n_samples,
            'valid_times': valid_times, 'base_labels': base_labels,'all_labels_str': all_labels_str
        }
        with open(preprocessed_data_cache_file, 'wb') as f: pd.to_pickle(data_to_cache, f)

    n_true_clusters = len(base_labels)
    print(f"âœ… ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†ã€‚å¯¾è±¡ã‚µãƒ³ãƒ—ãƒ«æ•°: {n_samples}, åŸºæœ¬ãƒ©ãƒ™ãƒ«æ•°: {n_true_clusters}")
    print("\n--- 2. ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒè¨­å®š ---")
    param_dist = {
        'data_input_order': ['normal_sort', 'month_sort', 'change_normal_sort', 'change_month_sort'], # ['normal_sort', 'month_sort', 'change_normal_sort', 'change_month_sort']
        'pca_n_components': pca_dims_to_test, 
        'include_time_features': [True, False], # [True, False]
        'gamma': (0.01, 3.0), 
        'beta': (0.001, 1.0),
        'learning_rate_W': (0.001, 0.1), 
        'learning_rate_lambda': (0.001, 0.1), 
        'learning_rate_Z': (0.001, 0.1),
        'initial_lambda_scalar': (0.001, 1.0), 
        'initial_lambda_vector_val': (0.001, 1.0), 
        'initial_lambda_crossterm_val': (-0.5, 0.5),
        'initial_Z_val': (0.01, 1.0), 
        'initial_Z_new_cluster': (0.01, 1.0), 
        'theta_new': (0.001, 1.0),  
        'Z_death_threshold': (0.01, 0.1),
        'death_patience_steps': [n_samples // 32, n_samples // 24, n_samples // 20, n_samples // 16, n_samples // 8, n_samples // 4, n_samples // 2, n_samples], 
        'num_epochs': [1000], 
        'activation_type': ['elliptical'] # ['circular', 'elliptical']
    }
    N_TRIALS = 10000
    fixed_params_for_acs = {'max_clusters': 50, 'initial_clusters': 1, 'lambda_min_val': 1e-7, 'bounds_W': (0, 1)}
    print(f"ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒæœ€å¤§è©¦è¡Œå›æ•°: {N_TRIALS}")
    print("\n--- 3. ä¸¦åˆ—ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒå®Ÿè¡Œ ---")
    num_processes_to_use = max(1, int(os.cpu_count() * 0.9)) if os.cpu_count() else 2
    tasks_for_pool = [] # å„è©¦è¡Œç”¨ã®ç‹¬ç«‹ã—ãŸä¹±æ•°ç”Ÿæˆå™¨ã‚’ä½œæˆ
    for i in range(N_TRIALS):
        trial_rng = random.Random(GLOBAL_SEED + i + 1)
        params = sample_random_params(param_dist, rng=trial_rng)
        tasks_for_pool.append(((i + 1, params), GLOBAL_SEED + i + 1))
    worker_func_with_fixed_args = partial(run_acs_trial, fixed_params_dict=fixed_params_for_acs, pca_data_dict=precalculated_pca_data, y_data_multi=y_true_multi, sin_time_data=sin_time, cos_time_data=cos_time, n_true_cls_worker=n_true_clusters, trial_log_dir_path=trial_logs_dir, label_encoder_worker=label_encoder, valid_times_worker=valid_times) # ğŸ’¡ valid_times_workerã‚’è¿½åŠ 
    start_search_time = datetime.datetime.now()
    all_trial_results = []
    with multiprocessing.Pool(processes=num_processes_to_use) as pool:
        for result in tqdm(pool.imap_unordered(worker_func_with_fixed_args, tasks_for_pool), total=N_TRIALS, desc="Random Search Progress"):
            all_trial_results.append(result)
    print(f"\nãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒå®Œäº†ã€‚ç·æ‰€è¦æ™‚é–“: {datetime.datetime.now() - start_search_time}")
    print("\n--- 4. çµæœé›†è¨ˆ (3ã¤ã®è©•ä¾¡æŒ‡æ¨™ã§ãƒ™ã‚¹ãƒˆã‚’é¸å‡º) ---")
    if not all_trial_results: sys.exit("ã‚¨ãƒ©ãƒ¼: ã‚µãƒ¼ãƒã‹ã‚‰çµæœãŒè¿”ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
    processed_results = []
    for res in all_trial_results:
        if res['error_traceback'] or not res['history']: continue
        history_df = pd.DataFrame(res['history'])
        best_by_composite = history_df.loc[history_df['composite_score'].idxmax()]
        best_by_bacc = history_df.loc[history_df['bacc'].idxmax()]
        best_by_accuracy = history_df.loc[history_df['accuracy'].idxmax()]
        processed_results.append({
            'trial_id': res['trial_count_from_worker'],
            'params': res['params_combo'],
            'random_state': res['acs_random_state_used'],
            'full_history': res['history'],
            'event_log': res['event_log'],
            'best_by_composite_score': best_by_composite.to_dict(),
            'best_by_bacc': best_by_bacc.to_dict(),
            'best_by_accuracy': best_by_accuracy.to_dict(),
        })

    if not processed_results: sys.exit("ã‚¨ãƒ©ãƒ¼: æœ‰åŠ¹ãªçµæœãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
    summary_df = pd.DataFrame([
        {
            'trial_id': r['trial_id'], **r['params'],
            'best_composite_score': r['best_by_composite_score']['composite_score'], 'best_composite_epoch': r['best_by_composite_score']['epoch'],
            'best_bacc': r['best_by_bacc']['bacc'], 'best_bacc_epoch': r['best_by_bacc']['epoch'],
            'best_accuracy': r['best_by_accuracy']['accuracy'], 'best_accuracy_epoch': r['best_by_accuracy']['epoch'],
        } for r in processed_results
    ])
    summary_df.to_csv(output_dir / f"random_search_summary_{timestamp}.csv", index=False)
    print(f"å…¨è©¦è¡Œã®ã‚µãƒãƒªãƒ¼ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã—ãŸ: {output_dir.resolve()}")
    top_results_map = {} # å„è©•ä¾¡æŒ‡æ¨™ã§ä¸Šä½3ä½ã¾ã§ã‚’å–å¾—
    for metric_name in ['composite_score', 'bacc', 'accuracy']:
        sorted_results = sorted(processed_results, 
                            key=lambda x: x[f'best_by_{metric_name}'][metric_name], 
                            reverse=True)
        top_results_map[metric_name] = sorted_results[:3]  # ä¸Šä½3ã¤ã‚’å–å¾—

    for metric_name, top_results in top_results_map.items(): # ä¸Šä½3ä½ã¾ã§ã®çµæœã‚’å‡¦ç†
        for rank, best_result_info in enumerate(top_results, 1):
            best_trial_id = best_result_info['trial_id']
            best_epoch_data = best_result_info[f'best_by_{metric_name}']
            best_epoch = int(best_epoch_data['epoch'])
            best_score = best_epoch_data[metric_name]
            best_params = best_result_info['params']
            best_random_state = best_result_info['random_state']
            run_output_dir = output_dir / f"{rank}_model_by_{metric_name}" # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã‚’1_model_by_*, 2_model_by_*, 3_model_by_*ã®å½¢å¼ã«
            os.makedirs(run_output_dir, exist_ok=True)
            best_event_log = best_result_info['event_log'] # è©¦è¡Œæ™‚ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ­ã‚°ã‚’ä¿å­˜
            if best_event_log:
                event_log_df = pd.DataFrame(best_event_log)
                log_save_path = run_output_dir / "trial_cluster_event_log.csv"
                event_log_df.to_csv(log_save_path, index=False)
                print(f"âœ… è©¦è¡Œæ™‚ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ­ã‚°ã‚’CSVã«ä¿å­˜ã—ã¾ã—ãŸ: {log_save_path.resolve()}")
            
            print("-" * 50)
            print(f"\n--- ç¬¬{rank}ä½ãƒ¢ãƒ‡ãƒ« (åŸºæº–: {metric_name.upper()}) ---")
            print(f"   Trial ID: {best_trial_id}, Best Epoch: {best_epoch}")
            print(f"ğŸ† Score ({metric_name}): {best_score:.4f}")
            print(f"   - Composite Score: {best_epoch_data['composite_score']:.4f}")
            print(f"   - Balanced Accuracy: {best_epoch_data['bacc']:.4f}")
            print(f"   - Accuracy: {best_epoch_data['accuracy']:.4f}")
            print(f"   - Final Clusters: {int(best_epoch_data['n_clusters'])}")
            print("   - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
            for k, v in best_params.items(): 
                print(f"     {k}: {v}")
            
            print(f"\n   å†å­¦ç¿’ã¨ãƒ—ãƒ­ãƒƒãƒˆç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã™... (å‡ºåŠ›å…ˆ: {run_output_dir.resolve()})")
            X_pca = precalculated_pca_data[best_params['pca_n_components']] # ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
            X_features = np.hstack([X_pca, sin_time, cos_time]) if best_params['include_time_features'] else X_pca
            X_scaled_data = MinMaxScaler().fit_transform(X_features).astype(np.float64)
            params_for_refit = {
                **fixed_params_for_acs, 
                **{k:v for k,v in best_params.items() if k not in ['pca_n_components', 'include_time_features', 'num_epochs', 'data_input_order']}, 
                'n_features': X_scaled_data.shape[1], 
                'random_state': best_random_state
            } # ACSãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šï¼ˆ'data_input_order' ã‚’é™¤å¤–ï¼‰
            best_model_instance = ACS(**params_for_refit)
            pca_visual = PCA(n_components=2, random_state=GLOBAL_SEED) # 2Då¯è¦–åŒ–ç”¨ã®PCAãƒ¢ãƒ‡ãƒ«
            X_pca_visual = pca_visual.fit_transform(X_scaled_data)
            np.random.seed(best_random_state) # å†å­¦ç¿’å‰ã«ä¹±æ•°çŠ¶æ…‹ã‚’å®Œå…¨ã«ãƒªã‚»ãƒƒãƒˆ
            random.seed(best_random_state)
            data_input_order = best_params['data_input_order'] # ãƒ‡ãƒ¼ã‚¿æŠ•å…¥é †åºã‚’å†ç¾ã™ã‚‹ãŸã‚ã®æº–å‚™ï¼ˆã‚·ãƒ¼ãƒ‰ã‚’æ˜ç¤ºçš„ã«æŒ‡å®šï¼‰
            initial_indices = get_sorted_indices(data_input_order, valid_times, random_seed=best_random_state)
            # partial_fit() ã‚’ä½¿ã£ãŸå†å­¦ç¿’ãƒ»å¯è¦–åŒ–ãƒ«ãƒ¼ãƒ—
            refit_history = []  # å†å­¦ç¿’æ™‚ã®å±¥æ­´ã‚’è¨˜éŒ²
            for epoch in tqdm(range(1, best_epoch + 1), desc=f"Refitting for {metric_name} (rank {rank})"):
                current_indices = initial_indices
                if 'change' in data_input_order and epoch % 2 == 0:
                    current_indices = initial_indices[::-1]
                for data_idx in current_indices:
                    U_p = X_scaled_data[data_idx, :]
                    best_model_instance.partial_fit(U_p, epoch=epoch, data_idx=int(data_idx))
                
                # å†å­¦ç¿’æ™‚ã®è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—
                preds = best_model_instance.predict(X_scaled_data)
                epoch_metrics = calculate_all_metrics_multi_label(preds, y_true_multi, label_encoder)
                epoch_metrics['epoch'] = epoch
                refit_history.append(epoch_metrics)
                plot_energy_contour_for_epoch(
                    model=best_model_instance, epoch=epoch, save_path=run_output_dir,
                    X_scaled_data_for_eval=X_scaled_data, X_pca_visual=X_pca_visual,
                    y_true_multi=y_true_multi, label_encoder=label_encoder,
                    pca_visual_model=pca_visual
                )
            
            # --- æœ€çµ‚çŠ¶æ…‹ã®ãƒ¬ãƒãƒ¼ãƒˆã¨å­¦ç¿’å±¥æ­´ã‚°ãƒ©ãƒ•ã®ä¿å­˜ ---
            final_preds = best_model_instance.predict(X_scaled_data)
            if best_model_instance.event_log:
                refit_event_log_df = pd.DataFrame(best_model_instance.event_log)
                refit_log_save_path = run_output_dir / "refit_cluster_event_log.csv"
                refit_event_log_df.to_csv(refit_log_save_path, index=False)
                print(f"âœ… å†å­¦ç¿’æ™‚ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ­ã‚°ã‚’CSVã«ä¿å­˜ã—ã¾ã—ãŸ: {refit_log_save_path.resolve()}")
            
            trial_log_path = run_output_dir / "trial_cluster_event_log.csv"
            refit_log_path = run_output_dir / "refit_cluster_event_log.csv"
            # è©•ä¾¡æŒ‡æ¨™ã®ä¸€è‡´æ¤œè¨¼
            print("\n--- è©•ä¾¡æŒ‡æ¨™ã®ä¸€è‡´æ¤œè¨¼ ---")
            # ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ¼ãƒæ™‚ã®æœ€è‰¯ã‚¨ãƒãƒƒã‚¯ã®æŒ‡æ¨™
            trial_best_metrics = best_epoch_data
            # å†å­¦ç¿’æ™‚ã®æœ€è‰¯ã‚¨ãƒãƒƒã‚¯ã®æŒ‡æ¨™
            refit_best_metrics = refit_history[best_epoch - 1]  # epochã¯1ã‹ã‚‰å§‹ã¾ã‚‹ãŸã‚-1
            # å„æŒ‡æ¨™ã®æ¯”è¼ƒ
            metrics_to_compare = ['composite_score', 'weighted_purity', 'accuracy', 'bacc', 'ari', 'n_clusters']
            all_metrics_match = True
            for metric in metrics_to_compare:
                trial_value = trial_best_metrics.get(metric, None)
                refit_value = refit_best_metrics.get(metric, None)
                if trial_value is None or refit_value is None:
                    print(f"   âš ï¸ {metric}: æ¯”è¼ƒä¸å¯ï¼ˆãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰")
                    continue
                
                # æ•°å€¤ã®æ¯”è¼ƒï¼ˆæµ®å‹•å°æ•°ç‚¹ã®èª¤å·®ã‚’è€ƒæ…®ï¼‰
                if isinstance(trial_value, (int, float)) and isinstance(refit_value, (int, float)):
                    if abs(trial_value - refit_value) < 1e-6:
                        print(f"   âœ… {metric}: ä¸€è‡´ (å€¤: {trial_value:.6f})")
                    else:
                        print(f"   âŒ {metric}: ä¸ä¸€è‡´ (Trial: {trial_value:.6f}, Refit: {refit_value:.6f}, å·®: {abs(trial_value - refit_value):.6f})")
                        all_metrics_match = False
                else:
                    if trial_value == refit_value:
                        print(f"   âœ… {metric}: ä¸€è‡´ (å€¤: {trial_value})")
                    else:
                        print(f"   âŒ {metric}: ä¸ä¸€è‡´ (Trial: {trial_value}, Refit: {refit_value})")
                        all_metrics_match = False
            
            if all_metrics_match:
                print("\n   âœ… [OK] ã™ã¹ã¦ã®è©•ä¾¡æŒ‡æ¨™ãŒä¸€è‡´ã—ã¾ã—ãŸã€‚å®Œå…¨ãªå†ç¾æ€§ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚")
            else:
                print("\n   âš ï¸ [NG] ä¸€éƒ¨ã®è©•ä¾¡æŒ‡æ¨™ãŒä¸€è‡´ã—ã¾ã›ã‚“ã§ã—ãŸã€‚")
            
            print("\n--- ã‚¤ãƒ™ãƒ³ãƒˆãƒ­ã‚°ã®ä¸€è‡´æ¤œè¨¼ ---")
            if trial_log_path.exists() and refit_log_path.exists():
                try:
                    df_trial = pd.read_csv(trial_log_path)
                    df_refit = pd.read_csv(refit_log_path)
                    are_logs_identical = df_trial.equals(df_refit)
                    if are_logs_identical:
                        print(f"âœ… [OK] trial ã¨ refit ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ­ã‚°ã¯å®Œå…¨ã«ä¸€è‡´ã—ã¾ã—ãŸã€‚å†ç¾æ€§ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚")
                    else:
                        print(f"âš ï¸ [NG] trial ã¨ refit ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ­ã‚°ã¯ä¸€è‡´ã—ã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®å‹•ä½œã«éæ±ºå®šçš„ãªè¦ç´ ãŒå«ã¾ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                        if len(df_trial) != len(df_refit):
                            print(f"   - è¡Œæ•°ãŒç•°ãªã‚Šã¾ã™: Trial={len(df_trial)}, Refit={len(df_refit)}")
                        else:
                            try:
                                pd.testing.assert_frame_equal(df_trial, df_refit, check_dtype=True)
                            except AssertionError as e:
                                print(f"   - å†…å®¹ã«å·®ç•°ãŒã‚ã‚Šã¾ã™ã€‚å·®åˆ†ã®è©³ç´°:\n{e}")
                except Exception as e:
                    print(f"   - ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¯”è¼ƒä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            else:
                print("   - æ¯”è¼ƒå¯¾è±¡ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€æ–¹ã¾ãŸã¯ä¸¡æ–¹ãŒå­˜åœ¨ã—ãªã„ãŸã‚ã€æ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            
            print("-" * 32)
            plot_cluster_composition(
                final_preds=final_preds,
                y_true_multi=y_true_multi,
                label_encoder=label_encoder,
                save_path=run_output_dir,
                metric_name=metric_name,
                trial_id=best_trial_id
            )
            plot_cluster_counts(
                final_preds=final_preds,
                y_true_multi=y_true_multi,
                label_encoder=label_encoder,
                save_path=run_output_dir,
                metric_name=metric_name,
                trial_id=best_trial_id
            )
            classification_df = pd.DataFrame({
                'valid_time': valid_times,
                'true_label_str': all_labels_str,
                'predicted_cluster': final_preds
            })
            classification_df.to_csv(run_output_dir / "classification_details.csv", index=False)
            print(f"âœ… å„ãƒ‡ãƒ¼ã‚¿ã®æ—¥ä»˜ã¨åˆ†é¡çµæœã‚’CSVã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
            # å†å­¦ç¿’æ™‚ã®å±¥æ­´ã‹ã‚‰å­¦ç¿’æ¨ç§»ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ
            history_df = pd.DataFrame(refit_history)  # å†å­¦ç¿’æ™‚ã®å±¥æ­´ã‚’ä½¿ç”¨
            fig_width = 12 + (best_epoch // 2000) * 4
            fig, axes = plt.subplots(3, 1, figsize=(fig_width, 15), sharex=True)
            fig.suptitle(f'ç¬¬{rank}ä½ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’æ¨ç§» (Trial {best_trial_id}, åŸºæº–: {metric_name.upper()}, å†å­¦ç¿’æ™‚)', fontsize=16)
            # 3ã¤ã®æŒ‡æ¨™ã‚’ãã‚Œãã‚Œãƒ—ãƒ­ãƒƒãƒˆ
            for i, (m_name, color) in enumerate([('composite_score', 'green'), ('bacc', 'purple'), ('accuracy', 'orange')]):
                axes[i].plot(history_df['epoch'], history_df[m_name], 's-', c=color, label=m_name)
                axes[i].set_ylabel(m_name, color=color)
                axes[i].tick_params(axis='y', labelcolor=color)
                ax2 = axes[i].twinx()
                ax2.plot(history_df['epoch'], history_df['n_clusters'], 'o--', c='tab:blue', alpha=0.6, label='Clusters')
                ax2.set_ylabel('Clusters', color='tab:blue')
                ax2.tick_params(axis='y', labelcolor='tab:blue')
                axes[i].axvline(x=best_epoch, color='red', linestyle='--', label=f'Best Epoch ({best_epoch})')
                axes[i].grid(True, axis='y', linestyle=':')
            
            axes[-1].set_xlabel('ã‚¨ãƒãƒƒã‚¯æ•°')
            fig.legend(loc="upper right", bbox_to_anchor=(1,1), bbox_transform=axes[0].transAxes)
            plt.tight_layout(rect=[0, 0.03, 1, 0.96])
            plt.savefig(run_output_dir / f"learning_history_{metric_name}.png", dpi=300)
            plt.close()
            print(f"âœ… ç¬¬{rank}ä½ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’æ¨ç§»ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")

    print("\n--- å…¨å‡¦ç†å®Œäº† ---")

if __name__ == '__main__':
    try:
        main_process_logic()
    except Exception as e:
        print("\n" + "="*30 + " FATAL ERROR " + "="*30)
        traceback.print_exc(file=sys.stdout)
        print("="*73)
    finally:
        if hasattr(sys.stdout, 'close') and callable(sys.stdout.close):
            sys.stdout.close()